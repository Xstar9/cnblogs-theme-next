{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23173b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T09:12:29.133397Z",
     "iopub.status.busy": "2023-08-16T09:12:29.132256Z",
     "iopub.status.idle": "2023-08-16T09:12:56.965799Z",
     "shell.execute_reply": "2023-08-16T09:12:56.964528Z"
    },
    "papermill": {
     "duration": 27.840439,
     "end_time": "2023-08-16T09:12:56.968320",
     "exception": false,
     "start_time": "2023-08-16T09:12:29.127881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!mkdir Model\n",
    "!mkdir -p Data/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b4077d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T09:12:56.975471Z",
     "iopub.status.busy": "2023-08-16T09:12:56.974583Z",
     "iopub.status.idle": "2023-08-16T09:12:59.726936Z",
     "shell.execute_reply": "2023-08-16T09:12:59.725778Z"
    },
    "papermill": {
     "duration": 2.758357,
     "end_time": "2023-08-16T09:12:59.729357",
     "exception": false,
     "start_time": "2023-08-16T09:12:56.971000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CodeJIT'...\r\n",
      "remote: Enumerating objects: 349, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (90/90), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (58/58), done.\u001b[K\r\n",
      "remote: Total 349 (delta 43), reused 76 (delta 31), pack-reused 259\u001b[K\r\n",
      "Receiving objects: 100% (349/349), 32.42 MiB | 26.60 MiB/s, done.\r\n",
      "Resolving deltas: 100% (202/202), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone -b master https://github.com/thanhtlx/CodeJIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0980666b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T09:12:59.738474Z",
     "iopub.status.busy": "2023-08-16T09:12:59.737553Z",
     "iopub.status.idle": "2023-08-16T09:13:00.674084Z",
     "shell.execute_reply": "2023-08-16T09:13:00.672919Z"
    },
    "papermill": {
     "duration": 0.943519,
     "end_time": "2023-08-16T09:13:00.676501",
     "exception": false,
     "start_time": "2023-08-16T09:12:59.732982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: ping: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!ping github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4704fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T09:13:00.686096Z",
     "iopub.status.busy": "2023-08-16T09:13:00.684638Z",
     "iopub.status.idle": "2023-08-16T09:13:00.689513Z",
     "shell.execute_reply": "2023-08-16T09:13:00.688661Z"
    },
    "papermill": {
     "duration": 0.011415,
     "end_time": "2023-08-16T09:13:00.691479",
     "exception": false,
     "start_time": "2023-08-16T09:13:00.680064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp -r /kaggle/input/codebert-embedding/code code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7efafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T09:13:00.699773Z",
     "iopub.status.busy": "2023-08-16T09:13:00.699279Z",
     "iopub.status.idle": "2023-08-16T10:55:38.124262Z",
     "shell.execute_reply": "2023-08-16T10:55:38.123040Z"
    },
    "papermill": {
     "duration": 6157.432038,
     "end_time": "2023-08-16T10:55:38.127044",
     "exception": false,
     "start_time": "2023-08-16T09:13:00.695006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n",
      "\r\n",
      "Training............\r\n",
      "\r\n",
      "data size: 16890\r\n",
      "Data(x=[821, 35], edge_index=[2, 1117], edge_attr=[1117, 3], edge_type=[1117], y=[1])\r\n",
      "RGCN(\r\n",
      "  (conv_0): RGCNConv(35, 32, num_relations=4)\r\n",
      "  (conv_1): RGCNConv(32, 32, num_relations=4)\r\n",
      "  (relu): ReLU(inplace=True)\r\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\r\n",
      ")\r\n",
      "learning rate :  0.0001\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 118.20657655994573 acc:0.5109780439121756\r\n",
      "curr: 1000 train loss: 137.95001141831 acc:0.4745254745254745\r\n",
      "curr: 1500 train loss: 126.09773242530356 acc:0.4816788807461692\r\n",
      "curr: 2000 train loss: 111.26504007931318 acc:0.49025487256371814\r\n",
      "curr: 2500 train loss: 101.09625590622049 acc:0.4894042383046781\r\n",
      "curr: 3000 train loss: 90.56690702356747 acc:0.4911696101299567\r\n",
      "curr: 3500 train loss: 81.71055493189577 acc:0.49557269351613825\r\n",
      "curr: 4000 train loss: 75.168722808208 acc:0.5031242189452637\r\n",
      "curr: 4500 train loss: 69.162085627775 acc:0.503443679182404\r\n",
      "curr: 5000 train loss: 65.20917551150688 acc:0.5032993401319736\r\n",
      "curr: 5500 train loss: 61.100847829679076 acc:0.5102708598436648\r\n",
      "curr: 6000 train loss: 58.57207599318563 acc:0.5112481253124479\r\n",
      "curr: 6500 train loss: 55.55233220647095 acc:0.5137671127518844\r\n",
      "curr: 7000 train loss: 52.580669099883934 acc:0.5153549492929581\r\n",
      "curr: 7500 train loss: 50.86066527719347 acc:0.5175309958672177\r\n",
      "curr: 8000 train loss: 48.57154713998934 acc:0.5208098987626547\r\n",
      "curr: 8500 train loss: 46.28885681263866 acc:0.5208798964827668\r\n",
      "curr: 9000 train loss: 44.36012961080111 acc:0.5233862904121764\r\n",
      "curr: 9500 train loss: 42.66429939785825 acc:0.5261551415640459\r\n",
      "curr: 10000 train loss: 41.255247598920754 acc:0.5272472752724727\r\n",
      "curr: 10500 train loss: 39.77365061316429 acc:0.5271878868679173\r\n",
      "curr: 11000 train loss: 38.468938844502965 acc:0.5282247068448322\r\n",
      "curr: 11500 train loss: 37.16794370483726 acc:0.5299539170506913\r\n",
      "curr: 12000 train loss: 35.99387550339642 acc:0.5307057745187901\r\n",
      "curr: 12500 train loss: 34.90201750758915 acc:0.533157347412207\r\n",
      "curr: 13000 train loss: 33.88150449649442 acc:0.5328820859933852\r\n",
      "curr: 13500 train loss: 32.93620090833903 acc:0.534997407599437\r\n",
      "curr: 14000 train loss: 31.960461760677756 acc:0.5361759874294694\r\n",
      "curr: 14500 train loss: 31.11201394162358 acc:0.5366526446451969\r\n",
      "curr: 15000 train loss: 30.23680413155594 acc:0.5372308512765815\r\n",
      "curr: 15500 train loss: 29.422185071794466 acc:0.5378362686278305\r\n",
      "curr: 16000 train loss: 28.65334667106399 acc:0.5380288731954253\r\n",
      "curr: 16500 train loss: 27.98316406860565 acc:0.5374825768135264\r\n",
      "correct: 9101\r\n",
      "epochs 1 train loss: 27.43738112457036 acc: 0.5388395500296033\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 4.9318084597182565 acc:0.5189620758483033\r\n",
      "curr: 1000 train loss: 10.653893446105537 acc:0.5304695304695305\r\n",
      "curr: 1500 train loss: 8.801302514946679 acc:0.5269820119920053\r\n",
      "curr: 2000 train loss: 7.819243085657283 acc:0.5337331334332833\r\n",
      "curr: 2500 train loss: 6.7914013898447765 acc:0.5437824870051979\r\n",
      "curr: 3000 train loss: 5.985965358179317 acc:0.5521492835721427\r\n",
      "curr: 3500 train loss: 5.912694287147981 acc:0.5549842902027992\r\n",
      "curr: 4000 train loss: 5.455804929395033 acc:0.5578605348662834\r\n",
      "curr: 4500 train loss: 5.192664431485912 acc:0.5638746945123306\r\n",
      "curr: 5000 train loss: 4.897250594142865 acc:0.5672865426914617\r\n",
      "curr: 5500 train loss: 4.782090879926251 acc:0.570623522995819\r\n",
      "curr: 6000 train loss: 4.7970316982146555 acc:0.5730711548075321\r\n",
      "curr: 6500 train loss: 4.7174496569505235 acc:0.5763728657129672\r\n",
      "curr: 7000 train loss: 4.494257651649515 acc:0.5789172975289244\r\n",
      "curr: 7500 train loss: 4.866637591329508 acc:0.5811225169977337\r\n",
      "curr: 8000 train loss: 4.66357554413168 acc:0.5854268216472941\r\n",
      "curr: 8500 train loss: 4.49609165115677 acc:0.5872250323491354\r\n",
      "curr: 9000 train loss: 4.326465985913685 acc:0.5897122541939784\r\n",
      "curr: 9500 train loss: 4.181117343146852 acc:0.5923586990843069\r\n",
      "curr: 10000 train loss: 4.225846214273408 acc:0.5926407359264073\r\n",
      "curr: 10500 train loss: 4.100577226108841 acc:0.5952766403199695\r\n",
      "curr: 11000 train loss: 3.9893413399644473 acc:0.5980365421325334\r\n",
      "curr: 11500 train loss: 3.897704272015195 acc:0.599947830623424\r\n",
      "curr: 12000 train loss: 3.795647160263798 acc:0.6002833097241896\r\n",
      "curr: 12500 train loss: 3.702693790805131 acc:0.60147188224942\r\n",
      "curr: 13000 train loss: 3.615640137571502 acc:0.6019536958695485\r\n",
      "curr: 13500 train loss: 3.5302405159924612 acc:0.6043256055107029\r\n",
      "curr: 14000 train loss: 3.4378271319735156 acc:0.6066709520748518\r\n",
      "curr: 14500 train loss: 3.3799094119283706 acc:0.6078891110957865\r\n",
      "curr: 15000 train loss: 3.3077854012660635 acc:0.6094927004866342\r\n",
      "curr: 15500 train loss: 3.2336270642021043 acc:0.610670279336817\r\n",
      "curr: 16000 train loss: 3.16898160444713 acc:0.6120867445784638\r\n",
      "curr: 16500 train loss: 3.1065714584935407 acc:0.6135991758075268\r\n",
      "correct: 10382\r\n",
      "epochs 2 train loss: 3.0563238180811174 acc: 0.6146832445233866\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 1.0490256938756168 acc:0.6526946107784432\r\n",
      "curr: 1000 train loss: 1.6631614202975786 acc:0.6383616383616384\r\n",
      "curr: 1500 train loss: 1.5666847903614658 acc:0.6289140572951366\r\n",
      "curr: 2000 train loss: 1.5536894342338339 acc:0.6226886556721639\r\n",
      "curr: 2500 train loss: 1.4884022074463816 acc:0.6221511395441823\r\n",
      "curr: 3000 train loss: 1.3964099847840956 acc:0.6297900699766744\r\n",
      "curr: 3500 train loss: 1.3105856512392886 acc:0.6326763781776635\r\n",
      "curr: 4000 train loss: 1.227705416737285 acc:0.6405898525368657\r\n",
      "curr: 4500 train loss: 1.190625605180733 acc:0.64407909353477\r\n",
      "curr: 5000 train loss: 1.1455194504820985 acc:0.6474705058988203\r\n",
      "curr: 5500 train loss: 1.2039240501562736 acc:0.6518814760952554\r\n",
      "curr: 6000 train loss: 1.2328116484171052 acc:0.6537243792701216\r\n",
      "curr: 6500 train loss: 1.2032647942911197 acc:0.6571296723580987\r\n",
      "curr: 7000 train loss: 1.1640003038018698 acc:0.6589058705899157\r\n",
      "curr: 7500 train loss: 1.2719443137518844 acc:0.6588454872683642\r\n",
      "curr: 8000 train loss: 1.2347536988199905 acc:0.6630421197350331\r\n",
      "curr: 8500 train loss: 1.202498459712242 acc:0.66474532407952\r\n",
      "curr: 9000 train loss: 1.1671014949459941 acc:0.6674813909565603\r\n",
      "curr: 9500 train loss: 1.143354780810719 acc:0.6683506999263236\r\n",
      "curr: 10000 train loss: 1.1872825299350855 acc:0.6695330466953304\r\n",
      "curr: 10500 train loss: 1.158919006491906 acc:0.6715550899914294\r\n",
      "curr: 11000 train loss: 1.1350742125221505 acc:0.6741205344968639\r\n",
      "curr: 11500 train loss: 1.122847009738873 acc:0.6744630901660725\r\n",
      "curr: 12000 train loss: 1.1027297957012825 acc:0.6756936921923173\r\n",
      "curr: 12500 train loss: 1.087562329091033 acc:0.6767458603311735\r\n",
      "curr: 13000 train loss: 1.0715766126500317 acc:0.6758710868394738\r\n",
      "curr: 13500 train loss: 1.054232978673582 acc:0.6767646840974743\r\n",
      "curr: 14000 train loss: 1.0403508067555316 acc:0.6772373401899864\r\n",
      "curr: 14500 train loss: 1.0295036541931626 acc:0.6783670091717813\r\n",
      "curr: 15000 train loss: 1.0157465490514221 acc:0.67895473635091\r\n",
      "curr: 15500 train loss: 1.0037366126273493 acc:0.6789239403909425\r\n",
      "curr: 16000 train loss: 0.9923382378539828 acc:0.6792700456221487\r\n",
      "curr: 16500 train loss: 0.9797009142061709 acc:0.6798981879886068\r\n",
      "correct: 11486\r\n",
      "epochs 3 train loss: 0.9712245039869882 acc: 0.6800473653049142\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.6644415200118271 acc:0.6586826347305389\r\n",
      "curr: 1000 train loss: 0.7042900060958399 acc:0.6423576423576424\r\n",
      "curr: 1500 train loss: 0.7008313344317514 acc:0.6528980679546968\r\n",
      "curr: 2000 train loss: 0.6814562749110462 acc:0.6546726636681659\r\n",
      "curr: 2500 train loss: 0.6880170786998254 acc:0.6477409036385445\r\n",
      "curr: 3000 train loss: 0.6758593029699819 acc:0.6584471842719094\r\n",
      "curr: 3500 train loss: 0.6704772190000811 acc:0.6620965438446158\r\n",
      "curr: 4000 train loss: 0.6601726905365356 acc:0.6695826043489128\r\n",
      "curr: 4500 train loss: 0.671488639747828 acc:0.6742946011997334\r\n",
      "curr: 5000 train loss: 0.6617837588652369 acc:0.6764647070585883\r\n",
      "curr: 5500 train loss: 0.6614939345908972 acc:0.6782403199418288\r\n",
      "curr: 6000 train loss: 0.6562675451710819 acc:0.6792201299783369\r\n",
      "curr: 6500 train loss: 0.6509154253568249 acc:0.6829718504845408\r\n",
      "curr: 7000 train loss: 0.6457547266264569 acc:0.6841879731466933\r\n",
      "curr: 7500 train loss: 0.6480227153123745 acc:0.6847087055059325\r\n",
      "curr: 8000 train loss: 0.640929739654074 acc:0.6871641044869391\r\n",
      "curr: 8500 train loss: 0.6370439892231807 acc:0.6885072344430067\r\n",
      "curr: 9000 train loss: 0.6311899989998496 acc:0.6904788356849239\r\n",
      "curr: 9500 train loss: 0.6286087681797122 acc:0.6907693926955057\r\n",
      "curr: 10000 train loss: 0.629620181037027 acc:0.6908309169083092\r\n",
      "curr: 10500 train loss: 0.6249345540350102 acc:0.6933625369012475\r\n",
      "curr: 11000 train loss: 0.6232361420920375 acc:0.6944823197891101\r\n",
      "curr: 11500 train loss: 0.6231346874463861 acc:0.6944613511868534\r\n",
      "curr: 12000 train loss: 0.6222592632666067 acc:0.6940254978751771\r\n",
      "curr: 12500 train loss: 0.6215983903233513 acc:0.6944244460443164\r\n",
      "curr: 13000 train loss: 0.6215807336604539 acc:0.6928697792477502\r\n",
      "curr: 13500 train loss: 0.6192164440207442 acc:0.6938004592252426\r\n",
      "curr: 14000 train loss: 0.6181746610355795 acc:0.6940932790514963\r\n",
      "curr: 14500 train loss: 0.6167248311372441 acc:0.6949865526515413\r\n",
      "curr: 15000 train loss: 0.6153713634111551 acc:0.6951536564229052\r\n",
      "curr: 15500 train loss: 0.6146908802831287 acc:0.6953744919682601\r\n",
      "curr: 16000 train loss: 0.6124946127062839 acc:0.6964564714705331\r\n",
      "curr: 16500 train loss: 0.6110267501453897 acc:0.6968062541664142\r\n",
      "correct: 11761\r\n",
      "epochs 4 train loss: 0.6111275810445503 acc: 0.6963291888691533\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.5949018399675086 acc:0.6846307385229541\r\n",
      "curr: 1000 train loss: 0.604591966178678 acc:0.6583416583416584\r\n",
      "curr: 1500 train loss: 0.6113623963619286 acc:0.6595602931379081\r\n",
      "curr: 2000 train loss: 0.6103813317234135 acc:0.6636681659170415\r\n",
      "curr: 2500 train loss: 0.6211452780947656 acc:0.6597361055577768\r\n",
      "curr: 3000 train loss: 0.6116577001866327 acc:0.6664445184938353\r\n",
      "curr: 3500 train loss: 0.606669447969741 acc:0.6723793201942302\r\n",
      "curr: 4000 train loss: 0.6019313268787077 acc:0.680579855036241\r\n",
      "curr: 4500 train loss: 0.6057265987457356 acc:0.6849588980226616\r\n",
      "curr: 5000 train loss: 0.6017261173598951 acc:0.6874625074985004\r\n",
      "curr: 5500 train loss: 0.5983950198597565 acc:0.6900563533902927\r\n",
      "curr: 6000 train loss: 0.596651283183235 acc:0.6913847692051325\r\n",
      "curr: 6500 train loss: 0.5908503076451159 acc:0.694662359636979\r\n",
      "curr: 7000 train loss: 0.5869190835614865 acc:0.6953292386801886\r\n",
      "curr: 7500 train loss: 0.5897128156184966 acc:0.6941741101186508\r\n",
      "curr: 8000 train loss: 0.586118872181213 acc:0.6962879640044994\r\n",
      "curr: 8500 train loss: 0.5853225500420792 acc:0.6974473591342195\r\n",
      "curr: 9000 train loss: 0.581740413839646 acc:0.6998111320964338\r\n",
      "curr: 9500 train loss: 0.5807888957914045 acc:0.69992632354489\r\n",
      "curr: 10000 train loss: 0.5803636149799393 acc:0.6999300069993001\r\n",
      "curr: 10500 train loss: 0.5788213040117535 acc:0.7010760879916198\r\n",
      "curr: 11000 train loss: 0.5785344341600511 acc:0.7021179892737024\r\n",
      "curr: 11500 train loss: 0.5797528927888631 acc:0.7016781149465264\r\n",
      "curr: 12000 train loss: 0.5797178197130672 acc:0.7016081993167236\r\n",
      "curr: 12500 train loss: 0.5795081961575342 acc:0.7018638508919286\r\n",
      "curr: 13000 train loss: 0.5797695832938836 acc:0.7006384124298131\r\n",
      "curr: 13500 train loss: 0.5787603742730486 acc:0.700836975038886\r\n",
      "curr: 14000 train loss: 0.5774798018981647 acc:0.7018784372544818\r\n",
      "curr: 14500 train loss: 0.5769108600402998 acc:0.7023653541135094\r\n",
      "curr: 15000 train loss: 0.5766017934274807 acc:0.701953203119792\r\n",
      "curr: 15500 train loss: 0.5772803504046314 acc:0.7022127604670666\r\n",
      "curr: 16000 train loss: 0.5766845140011139 acc:0.702393600399975\r\n",
      "curr: 16500 train loss: 0.5757243733320515 acc:0.7028058905520878\r\n",
      "correct: 11868\r\n",
      "epochs 5 train loss: 0.5761673937718039 acc: 0.702664298401421\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.6249291783190813 acc:0.6986027944111777\r\n",
      "curr: 1000 train loss: 0.6149041749086509 acc:0.6693306693306693\r\n",
      "curr: 1500 train loss: 0.6088013089604403 acc:0.6775483011325782\r\n",
      "curr: 2000 train loss: 0.59980389932778 acc:0.679160419790105\r\n",
      "curr: 2500 train loss: 0.6163066688314571 acc:0.6721311475409836\r\n",
      "curr: 3000 train loss: 0.6070684010178304 acc:0.6781072975674776\r\n",
      "curr: 3500 train loss: 0.6042362218835569 acc:0.6778063410454156\r\n",
      "curr: 4000 train loss: 0.599061334123931 acc:0.6870782304423894\r\n",
      "curr: 4500 train loss: 0.5973658684864698 acc:0.6918462563874694\r\n",
      "curr: 5000 train loss: 0.5930386561502076 acc:0.6944611077784443\r\n",
      "curr: 5500 train loss: 0.5916631332262832 acc:0.6960552626795128\r\n",
      "curr: 6000 train loss: 0.5930258496610467 acc:0.6970504915847359\r\n",
      "curr: 6500 train loss: 0.5895447213753742 acc:0.7001999692355022\r\n",
      "curr: 7000 train loss: 0.5855581831747281 acc:0.701185544922154\r\n",
      "curr: 7500 train loss: 0.5881721648545613 acc:0.7005732568990801\r\n",
      "curr: 8000 train loss: 0.5848296390644179 acc:0.7019122609673791\r\n",
      "curr: 8500 train loss: 0.5832214747754497 acc:0.7032113868956593\r\n",
      "curr: 9000 train loss: 0.5801707173390205 acc:0.7050327741362071\r\n",
      "curr: 9500 train loss: 0.5791183733031507 acc:0.7057151878749606\r\n",
      "curr: 10000 train loss: 0.5797644911206291 acc:0.7055294470552945\r\n",
      "curr: 10500 train loss: 0.5778486798036443 acc:0.7073612036948862\r\n",
      "curr: 11000 train loss: 0.5776209920657646 acc:0.7083901463503318\r\n",
      "curr: 11500 train loss: 0.5782880424787294 acc:0.7080253890966003\r\n",
      "curr: 12000 train loss: 0.5784293566572283 acc:0.7074410465794517\r\n",
      "curr: 12500 train loss: 0.5782514753128652 acc:0.7076233901287897\r\n",
      "curr: 13000 train loss: 0.5785554863487263 acc:0.7064841166064149\r\n",
      "curr: 13500 train loss: 0.5779518933542716 acc:0.7066883934523369\r\n",
      "curr: 14000 train loss: 0.5770304138676149 acc:0.7070923505463895\r\n",
      "curr: 14500 train loss: 0.5760061705452211 acc:0.7079511757809807\r\n",
      "curr: 15000 train loss: 0.575057159230228 acc:0.7084861009266049\r\n",
      "curr: 15500 train loss: 0.5755558149330462 acc:0.7082768853622347\r\n",
      "curr: 16000 train loss: 0.5742743398228897 acc:0.7087057058933817\r\n",
      "curr: 16500 train loss: 0.5734555637335981 acc:0.7086237197745591\r\n",
      "correct: 11963\r\n",
      "epochs 6 train loss: 0.5735023075261185 acc: 0.7082889283599764\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.7712253980551508 acc:0.7045908183632734\r\n",
      "curr: 1000 train loss: 0.6940150577326243 acc:0.6683316683316683\r\n",
      "curr: 1500 train loss: 0.6548241605679744 acc:0.676215856095936\r\n",
      "curr: 2000 train loss: 0.6314304072235091 acc:0.6806596701649176\r\n",
      "curr: 2500 train loss: 0.6403646169742705 acc:0.6765293882447021\r\n",
      "curr: 3000 train loss: 0.626503777184523 acc:0.6817727424191936\r\n",
      "curr: 3500 train loss: 0.6183081275171685 acc:0.6852327906312482\r\n",
      "curr: 4000 train loss: 0.6104100534400788 acc:0.6933266683329168\r\n",
      "curr: 4500 train loss: 0.6073349562556477 acc:0.6978449233503666\r\n",
      "curr: 5000 train loss: 0.6011808974800172 acc:0.7000599880023995\r\n",
      "curr: 5500 train loss: 0.5978210290825372 acc:0.6995091801490638\r\n",
      "curr: 6000 train loss: 0.5961565429623175 acc:0.6985502416263956\r\n",
      "curr: 6500 train loss: 0.5899420121087882 acc:0.7009690816797416\r\n",
      "curr: 7000 train loss: 0.5852784901666679 acc:0.7023282388230253\r\n",
      "curr: 7500 train loss: 0.5874914704467034 acc:0.7017730969204106\r\n",
      "curr: 8000 train loss: 0.5837582283714546 acc:0.7035370578677665\r\n",
      "curr: 8500 train loss: 0.5825222795246388 acc:0.7040348194330078\r\n",
      "curr: 9000 train loss: 0.5791328803797301 acc:0.706477058104655\r\n",
      "curr: 9500 train loss: 0.5780700900359257 acc:0.7062414482686034\r\n",
      "curr: 10000 train loss: 0.5783828761300432 acc:0.7061293870612939\r\n",
      "curr: 10500 train loss: 0.5760417194760784 acc:0.7079325778497286\r\n",
      "curr: 11000 train loss: 0.5747154954228234 acc:0.709117352967912\r\n",
      "curr: 11500 train loss: 0.5752593850109394 acc:0.7090687766281193\r\n",
      "curr: 12000 train loss: 0.5749712987646174 acc:0.7094408799266728\r\n",
      "curr: 12500 train loss: 0.574961525605601 acc:0.7097032237421006\r\n",
      "curr: 13000 train loss: 0.5751305361553485 acc:0.7088685485731867\r\n",
      "curr: 13500 train loss: 0.5740958195435221 acc:0.7091326568402341\r\n",
      "curr: 14000 train loss: 0.5726086562591378 acc:0.7100207128062281\r\n",
      "curr: 14500 train loss: 0.5712596249936167 acc:0.7112612923246673\r\n",
      "curr: 15000 train loss: 0.5707307634787075 acc:0.7118192120525298\r\n",
      "curr: 15500 train loss: 0.571237839393689 acc:0.7118895555125476\r\n",
      "curr: 16000 train loss: 0.5701531372614982 acc:0.7121429910630586\r\n",
      "curr: 16500 train loss: 0.569267136614763 acc:0.7120780558754015\r\n",
      "correct: 12024\r\n",
      "epochs 7 train loss: 0.5693728000990929 acc: 0.7119005328596802\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.5555492978595732 acc:0.7105788423153693\r\n",
      "curr: 1000 train loss: 0.5710418485912044 acc:0.6883116883116883\r\n",
      "curr: 1500 train loss: 0.5712591297900111 acc:0.6888740839440373\r\n",
      "curr: 2000 train loss: 0.5637362242196102 acc:0.6951524237881059\r\n",
      "curr: 2500 train loss: 0.5940182064735863 acc:0.68812475009996\r\n",
      "curr: 3000 train loss: 0.5899102188652764 acc:0.6927690769743419\r\n",
      "curr: 3500 train loss: 0.5876613125415029 acc:0.6940874035989717\r\n",
      "curr: 4000 train loss: 0.5832648489396328 acc:0.7008247938015496\r\n",
      "curr: 4500 train loss: 0.5832384533168758 acc:0.70228838035992\r\n",
      "curr: 5000 train loss: 0.5788844440416968 acc:0.7048590281943611\r\n",
      "curr: 5500 train loss: 0.5766918750406813 acc:0.7055080894382839\r\n",
      "curr: 6000 train loss: 0.5774649804971129 acc:0.704215964005999\r\n",
      "curr: 6500 train loss: 0.5719743883163858 acc:0.7060452238117213\r\n",
      "curr: 7000 train loss: 0.5684290811873292 acc:0.7063276674760749\r\n",
      "curr: 7500 train loss: 0.5717146857632591 acc:0.7043060925209972\r\n",
      "curr: 8000 train loss: 0.5684495459386251 acc:0.7060367454068242\r\n",
      "curr: 8500 train loss: 0.5679284437535645 acc:0.7073285495824021\r\n",
      "curr: 9000 train loss: 0.5656638031171948 acc:0.7089212309743362\r\n",
      "curr: 9500 train loss: 0.5655321949107094 acc:0.7087674981580886\r\n",
      "curr: 10000 train loss: 0.5659369485981078 acc:0.7088291170882912\r\n",
      "curr: 10500 train loss: 0.56411317747327 acc:0.7103133034949053\r\n",
      "curr: 11000 train loss: 0.5629688892363228 acc:0.7114807744750478\r\n",
      "curr: 11500 train loss: 0.5639193325038792 acc:0.7117641944178767\r\n",
      "curr: 12000 train loss: 0.5643510358873942 acc:0.7121906507791017\r\n",
      "curr: 12500 train loss: 0.5646117677182948 acc:0.7121830253579714\r\n",
      "curr: 13000 train loss: 0.5648216335765821 acc:0.7107914775786478\r\n",
      "curr: 13500 train loss: 0.5637109605701979 acc:0.7113547144655952\r\n",
      "curr: 14000 train loss: 0.562401217676783 acc:0.7121634168987929\r\n",
      "curr: 14500 train loss: 0.561121166382382 acc:0.7135369974484518\r\n",
      "curr: 15000 train loss: 0.5603798344137926 acc:0.7140190653956403\r\n",
      "curr: 15500 train loss: 0.5609380292249971 acc:0.7138894264886136\r\n",
      "curr: 16000 train loss: 0.5599060545154098 acc:0.7145178426348353\r\n",
      "curr: 16500 train loss: 0.5590730808967816 acc:0.7150475728743713\r\n",
      "correct: 12069\r\n",
      "epochs 8 train loss: 0.5594079193701096 acc: 0.7145648312611013\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.528406482759655 acc:0.7405189620758483\r\n",
      "curr: 1000 train loss: 0.5628781963157415 acc:0.6863136863136863\r\n",
      "curr: 1500 train loss: 0.5611810424444625 acc:0.6948700866089274\r\n",
      "curr: 2000 train loss: 0.559614214696611 acc:0.6991504247876063\r\n",
      "curr: 2500 train loss: 0.5629563169195928 acc:0.6913234706117553\r\n",
      "curr: 3000 train loss: 0.5616655178127524 acc:0.6944351882705765\r\n",
      "curr: 3500 train loss: 0.5616126877776155 acc:0.6963724650099972\r\n",
      "curr: 4000 train loss: 0.5603443703608928 acc:0.7020744813796551\r\n",
      "curr: 4500 train loss: 0.5605206559663195 acc:0.7058431459675628\r\n",
      "curr: 5000 train loss: 0.5586705401272276 acc:0.7088582283543291\r\n",
      "curr: 5500 train loss: 0.5570735226559859 acc:0.7098709325577168\r\n",
      "curr: 6000 train loss: 0.561677706286195 acc:0.7093817697050492\r\n",
      "curr: 6500 train loss: 0.5570499814297721 acc:0.7115828334102445\r\n",
      "curr: 7000 train loss: 0.5548932410304349 acc:0.7113269532923868\r\n",
      "curr: 7500 train loss: 0.5585482440087 acc:0.7104386081855752\r\n",
      "curr: 8000 train loss: 0.5561782454116786 acc:0.7117860267466567\r\n",
      "curr: 8500 train loss: 0.5563625708324054 acc:0.711563345488766\r\n",
      "curr: 9000 train loss: 0.5542424352303261 acc:0.7132540828796801\r\n",
      "curr: 9500 train loss: 0.5542989447312937 acc:0.7135038417008736\r\n",
      "curr: 10000 train loss: 0.554326216032244 acc:0.7134286571342866\r\n",
      "curr: 10500 train loss: 0.5526711921088706 acc:0.7152652128368727\r\n",
      "curr: 11000 train loss: 0.5507103512078273 acc:0.7164803199709118\r\n",
      "curr: 11500 train loss: 0.5531761022010546 acc:0.7160246935049126\r\n",
      "curr: 12000 train loss: 0.5535592213138744 acc:0.7156903591367386\r\n",
      "curr: 12500 train loss: 0.55377201217784 acc:0.7161827053835693\r\n",
      "curr: 13000 train loss: 0.5537387849656008 acc:0.7150988385508807\r\n",
      "curr: 13500 train loss: 0.5531162674670229 acc:0.7165395155914377\r\n",
      "curr: 14000 train loss: 0.5523534854804102 acc:0.717091636311692\r\n",
      "curr: 14500 train loss: 0.5512629298832483 acc:0.7181573684573478\r\n",
      "curr: 15000 train loss: 0.5505426988563414 acc:0.7186187587494167\r\n",
      "curr: 15500 train loss: 0.5514380807802315 acc:0.7184052641765047\r\n",
      "curr: 16000 train loss: 0.5506058245119473 acc:0.7189550653084182\r\n",
      "curr: 16500 train loss: 0.5497013629348709 acc:0.7194715471789589\r\n",
      "correct: 12145\r\n",
      "epochs 9 train loss: 0.5501992046138128 acc: 0.7190645352279456\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.5043484498434615 acc:0.7425149700598802\r\n",
      "curr: 1000 train loss: 0.5492663091555795 acc:0.6933066933066933\r\n",
      "curr: 1500 train loss: 0.5459056758537224 acc:0.704197201865423\r\n",
      "curr: 2000 train loss: 0.5375212619841784 acc:0.7071464267866067\r\n",
      "curr: 2500 train loss: 0.5480435479252151 acc:0.7029188324670131\r\n",
      "curr: 3000 train loss: 0.5494415110450483 acc:0.7067644118627124\r\n",
      "curr: 3500 train loss: 0.5499657311111433 acc:0.707512139388746\r\n",
      "curr: 4000 train loss: 0.5489889963313295 acc:0.7133216695826043\r\n",
      "curr: 4500 train loss: 0.5492037421915784 acc:0.7147300599866696\r\n",
      "curr: 5000 train loss: 0.5475877254501812 acc:0.7174565086982604\r\n",
      "curr: 5500 train loss: 0.546294577411822 acc:0.7187784039265588\r\n",
      "curr: 6000 train loss: 0.5495581007890644 acc:0.7175470754874188\r\n",
      "curr: 6500 train loss: 0.5447413128497245 acc:0.7197354253191817\r\n",
      "curr: 7000 train loss: 0.5436602995181481 acc:0.7184687901728325\r\n",
      "curr: 7500 train loss: 0.5471187312587215 acc:0.7164378082922277\r\n",
      "curr: 8000 train loss: 0.5452829862517555 acc:0.7180352455943008\r\n",
      "curr: 8500 train loss: 0.5454976887472293 acc:0.7174450064698271\r\n",
      "curr: 9000 train loss: 0.5437454246398438 acc:0.7190312187534719\r\n",
      "curr: 9500 train loss: 0.5442368602909227 acc:0.719082201873487\r\n",
      "curr: 10000 train loss: 0.5448404105593379 acc:0.7191280871912809\r\n",
      "curr: 10500 train loss: 0.543302741801508 acc:0.721550328540139\r\n",
      "curr: 11000 train loss: 0.5411524998561804 acc:0.7237523861467139\r\n",
      "curr: 11500 train loss: 0.5413227010005963 acc:0.7236762020693853\r\n",
      "curr: 12000 train loss: 0.5415542244913275 acc:0.7241896508624281\r\n",
      "curr: 12500 train loss: 0.5419402587328372 acc:0.724662027037837\r\n",
      "curr: 13000 train loss: 0.5421070125669896 acc:0.7239443119760018\r\n",
      "curr: 13500 train loss: 0.5414471410303116 acc:0.7246870602177616\r\n",
      "curr: 14000 train loss: 0.5401430762303053 acc:0.72594814656096\r\n",
      "curr: 14500 train loss: 0.5388853947131133 acc:0.7274670712364665\r\n",
      "curr: 15000 train loss: 0.5381043988315786 acc:0.7279514699020065\r\n",
      "curr: 15500 train loss: 0.538843932842755 acc:0.7277594993871364\r\n",
      "curr: 16000 train loss: 0.538345746096934 acc:0.7283919755015311\r\n",
      "curr: 16500 train loss: 0.5371338168388221 acc:0.7291679292164112\r\n",
      "correct: 12306\r\n",
      "epochs 10 train loss: 0.537779176826198 acc: 0.7285968028419183\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.5098704466245424 acc:0.7564870259481038\r\n",
      "curr: 1000 train loss: 0.5412510680236085 acc:0.7092907092907093\r\n",
      "curr: 1500 train loss: 0.5338779455685376 acc:0.7201865423051299\r\n",
      "curr: 2000 train loss: 0.5267170568915077 acc:0.7226386806596702\r\n",
      "curr: 2500 train loss: 0.5478765980841153 acc:0.7157137145141943\r\n",
      "curr: 3000 train loss: 0.5491621312206406 acc:0.7170943018993668\r\n",
      "curr: 3500 train loss: 0.5479324956238408 acc:0.7175092830619823\r\n",
      "curr: 4000 train loss: 0.5458274219144057 acc:0.7228192951762059\r\n",
      "curr: 4500 train loss: 0.5461599199030117 acc:0.7245056654076871\r\n",
      "curr: 5000 train loss: 0.5465927403555922 acc:0.7260547890421916\r\n",
      "curr: 5500 train loss: 0.544765046071752 acc:0.7264133793855663\r\n",
      "curr: 6000 train loss: 0.5456895966261307 acc:0.7250458256957174\r\n",
      "curr: 6500 train loss: 0.5408522681453228 acc:0.7269650822950315\r\n",
      "curr: 7000 train loss: 0.5396750628013136 acc:0.7271818311669761\r\n",
      "curr: 7500 train loss: 0.5437021136113439 acc:0.7245700573256899\r\n",
      "curr: 8000 train loss: 0.5420990135253151 acc:0.7254093238345207\r\n",
      "curr: 8500 train loss: 0.5422835933874866 acc:0.7250911657452065\r\n",
      "curr: 9000 train loss: 0.5408716981377556 acc:0.7262526385957115\r\n",
      "curr: 9500 train loss: 0.5413321051852835 acc:0.7251868224397432\r\n",
      "curr: 10000 train loss: 0.5420155599575093 acc:0.7247275272472753\r\n",
      "curr: 10500 train loss: 0.5400227988621872 acc:0.7262165508046853\r\n",
      "curr: 11000 train loss: 0.5374543663286784 acc:0.7282974275065903\r\n",
      "curr: 11500 train loss: 0.5389443204614255 acc:0.7287192418050604\r\n",
      "curr: 12000 train loss: 0.5396400814503524 acc:0.7286892758936755\r\n",
      "curr: 12500 train loss: 0.5391249441176085 acc:0.7296216302695784\r\n",
      "curr: 13000 train loss: 0.5389972612614702 acc:0.7289439273902008\r\n",
      "curr: 13500 train loss: 0.5381607768788824 acc:0.7303903414561884\r\n",
      "curr: 14000 train loss: 0.5368749726727022 acc:0.7310192129133634\r\n",
      "curr: 14500 train loss: 0.5353465345900751 acc:0.732225363768016\r\n",
      "curr: 15000 train loss: 0.5344065389726845 acc:0.7326178254783015\r\n",
      "curr: 15500 train loss: 0.5351310998714846 acc:0.7322108251080576\r\n",
      "curr: 16000 train loss: 0.5343488802603973 acc:0.733266670833073\r\n",
      "curr: 16500 train loss: 0.532982597163508 acc:0.7333494939700624\r\n",
      "correct: 12382\r\n",
      "epochs 11 train loss: 0.5336174045645723 acc: 0.7330965068087626\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.617376592093293 acc:0.7664670658682635\r\n",
      "curr: 1000 train loss: 0.5970415007273221 acc:0.7092907092907093\r\n",
      "curr: 1500 train loss: 0.5677455627264625 acc:0.7135243171219188\r\n",
      "curr: 2000 train loss: 0.5468920542028564 acc:0.719640179910045\r\n",
      "curr: 2500 train loss: 0.5454772607868389 acc:0.7137145141943223\r\n",
      "curr: 3000 train loss: 0.5450256799015241 acc:0.716427857380873\r\n",
      "curr: 3500 train loss: 0.5437393596798044 acc:0.7172236503856041\r\n",
      "curr: 4000 train loss: 0.5436280613004262 acc:0.7215696075981005\r\n",
      "curr: 4500 train loss: 0.5463822561815442 acc:0.7227282826038658\r\n",
      "curr: 5000 train loss: 0.5450049064004537 acc:0.7242551489702059\r\n",
      "curr: 5500 train loss: 0.544356217511815 acc:0.7240501726958735\r\n",
      "curr: 6000 train loss: 0.5454320121279036 acc:0.7237127145475754\r\n",
      "curr: 6500 train loss: 0.5401509623642674 acc:0.7268112598061837\r\n",
      "curr: 7000 train loss: 0.5388861332684374 acc:0.7267533209541495\r\n",
      "curr: 7500 train loss: 0.5419327428499734 acc:0.7249700039994668\r\n",
      "curr: 8000 train loss: 0.5399892024278281 acc:0.7259092613423322\r\n",
      "curr: 8500 train loss: 0.540946533380682 acc:0.7257969650629338\r\n",
      "curr: 9000 train loss: 0.5397584912389929 acc:0.726474836129319\r\n",
      "curr: 9500 train loss: 0.5400146121121419 acc:0.7265550994632144\r\n",
      "curr: 10000 train loss: 0.5404153029967305 acc:0.7262273772622738\r\n",
      "curr: 10500 train loss: 0.5385388911570176 acc:0.728787734501476\r\n",
      "curr: 11000 train loss: 0.5362377357350119 acc:0.7305699481865285\r\n",
      "curr: 11500 train loss: 0.5376915976714599 acc:0.7306321189461786\r\n",
      "curr: 12000 train loss: 0.5375502495233478 acc:0.7308557620198317\r\n",
      "curr: 12500 train loss: 0.537069972114852 acc:0.7316214702823775\r\n",
      "curr: 13000 train loss: 0.5368527289500757 acc:0.7307130220752249\r\n",
      "curr: 13500 train loss: 0.5357166784167863 acc:0.7317976446189172\r\n",
      "curr: 14000 train loss: 0.5340748914642163 acc:0.732661952717663\r\n",
      "curr: 14500 train loss: 0.5319478289334921 acc:0.7340873043238397\r\n",
      "curr: 15000 train loss: 0.5310985973909969 acc:0.7344177054863009\r\n",
      "curr: 15500 train loss: 0.5316395573844384 acc:0.7341461841171537\r\n",
      "curr: 16000 train loss: 0.5305598860012173 acc:0.7352665458408849\r\n",
      "curr: 16500 train loss: 0.5291326535435785 acc:0.7359553966426278\r\n",
      "correct: 12425\r\n",
      "epochs 12 train loss: 0.5301501836431232 acc: 0.7356423919478982\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.5041942462822951 acc:0.7884231536926147\r\n",
      "curr: 1000 train loss: 0.5342660171052336 acc:0.7232767232767233\r\n",
      "curr: 1500 train loss: 0.5207797620082159 acc:0.7315123251165889\r\n",
      "curr: 2000 train loss: 0.5082251979168184 acc:0.7341329335332334\r\n",
      "curr: 2500 train loss: 0.5235180854004372 acc:0.7233106757297081\r\n",
      "curr: 3000 train loss: 0.5279308382815145 acc:0.7217594135288238\r\n",
      "curr: 3500 train loss: 0.5281986768355547 acc:0.7229363039131677\r\n",
      "curr: 4000 train loss: 0.5295213547931279 acc:0.7263184203949012\r\n",
      "curr: 4500 train loss: 0.5296620837248143 acc:0.7285047767162852\r\n",
      "curr: 5000 train loss: 0.5293730788433796 acc:0.7304539092181563\r\n",
      "curr: 5500 train loss: 0.5290940378456629 acc:0.73023086711507\r\n",
      "curr: 6000 train loss: 0.5310902061324073 acc:0.7290451591401433\r\n",
      "curr: 6500 train loss: 0.5274820729254663 acc:0.7305029995385325\r\n",
      "curr: 7000 train loss: 0.5267970493022894 acc:0.7298957291815454\r\n",
      "curr: 7500 train loss: 0.5320437301253054 acc:0.7281695773896814\r\n",
      "curr: 8000 train loss: 0.530930109803319 acc:0.7285339332583427\r\n",
      "curr: 8500 train loss: 0.5316930832808465 acc:0.7279143630161158\r\n",
      "curr: 9000 train loss: 0.530612659799453 acc:0.7293634040662149\r\n",
      "curr: 9500 train loss: 0.5309795350085716 acc:0.7296074097463425\r\n",
      "curr: 10000 train loss: 0.5314952077872215 acc:0.7295270472952705\r\n",
      "curr: 10500 train loss: 0.5299298394689962 acc:0.7320255213789163\r\n",
      "curr: 11000 train loss: 0.5271603679694661 acc:0.7346604854104173\r\n",
      "curr: 11500 train loss: 0.5274769375363245 acc:0.7348926180332145\r\n",
      "curr: 12000 train loss: 0.527473953691793 acc:0.7353553870510791\r\n",
      "curr: 12500 train loss: 0.5274807851720409 acc:0.7361011119110471\r\n",
      "curr: 13000 train loss: 0.5275738495375766 acc:0.7353280516883317\r\n",
      "curr: 13500 train loss: 0.5264235543641912 acc:0.7364639656321754\r\n",
      "curr: 14000 train loss: 0.5246031663967644 acc:0.7374473251910578\r\n",
      "curr: 14500 train loss: 0.5225317030558484 acc:0.7390524791393697\r\n",
      "curr: 15000 train loss: 0.5212655390076166 acc:0.7402839810679288\r\n",
      "curr: 15500 train loss: 0.5222224132923022 acc:0.7397587252435327\r\n",
      "curr: 16000 train loss: 0.5215799206142255 acc:0.7403287294544091\r\n",
      "curr: 16500 train loss: 0.5201701069951263 acc:0.7405611781104176\r\n",
      "correct: 12497\r\n",
      "epochs 13 train loss: 0.5212341688702379 acc: 0.7399052693901716\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.4426652958390665 acc:0.7884231536926147\r\n",
      "curr: 1000 train loss: 0.5002042482643357 acc:0.7232767232767233\r\n",
      "curr: 1500 train loss: 0.4944935642588297 acc:0.7275149900066622\r\n",
      "curr: 2000 train loss: 0.48776081475375566 acc:0.7326336831584208\r\n",
      "curr: 2500 train loss: 0.49830725636753076 acc:0.726109556177529\r\n",
      "curr: 3000 train loss: 0.5075973081464724 acc:0.7250916361212929\r\n",
      "curr: 3500 train loss: 0.5108611791826333 acc:0.7220794058840332\r\n",
      "curr: 4000 train loss: 0.515059536557305 acc:0.7243189202699325\r\n",
      "curr: 4500 train loss: 0.5182739593593296 acc:0.7271717396134192\r\n",
      "curr: 5000 train loss: 0.519651136323774 acc:0.7288542291541692\r\n",
      "curr: 5500 train loss: 0.5190320460596126 acc:0.7291401563352118\r\n",
      "curr: 6000 train loss: 0.5213589951560264 acc:0.7272121313114481\r\n",
      "curr: 6500 train loss: 0.5175435777733542 acc:0.7301953545608368\r\n",
      "curr: 7000 train loss: 0.5177891410288867 acc:0.7294672189687188\r\n",
      "curr: 7500 train loss: 0.522176755538879 acc:0.7276363151579789\r\n",
      "curr: 8000 train loss: 0.5215491808528556 acc:0.7284089488813899\r\n",
      "curr: 8500 train loss: 0.5224864248399439 acc:0.728031996235737\r\n",
      "curr: 9000 train loss: 0.5219763305420357 acc:0.7295856015998222\r\n",
      "curr: 9500 train loss: 0.5230481509932319 acc:0.7296074097463425\r\n",
      "curr: 10000 train loss: 0.5239977312227456 acc:0.7291270872912708\r\n",
      "curr: 10500 train loss: 0.5225187595660047 acc:0.7324064374821445\r\n",
      "curr: 11000 train loss: 0.5200665001218342 acc:0.7349331878920098\r\n",
      "curr: 11500 train loss: 0.5207611110507893 acc:0.7350665159551343\r\n",
      "curr: 12000 train loss: 0.5206605442752824 acc:0.7354387134405467\r\n",
      "curr: 12500 train loss: 0.5209960143852015 acc:0.736261099112071\r\n",
      "curr: 13000 train loss: 0.5211940669845535 acc:0.7354049688485501\r\n",
      "curr: 13500 train loss: 0.5206400019524885 acc:0.7363158284571513\r\n",
      "curr: 14000 train loss: 0.5189019108484983 acc:0.7378044425398186\r\n",
      "curr: 14500 train loss: 0.5171330857624075 acc:0.739673125991311\r\n",
      "curr: 15000 train loss: 0.5162835557310537 acc:0.7402839810679288\r\n",
      "curr: 15500 train loss: 0.5174820259820982 acc:0.7397587252435327\r\n",
      "curr: 16000 train loss: 0.5174189342517522 acc:0.7403287294544091\r\n",
      "curr: 16500 train loss: 0.5159621123044017 acc:0.740924792436822\r\n",
      "correct: 12508\r\n",
      "epochs 14 train loss: 0.5168416594225198 acc: 0.7405565423327413\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.4444524982776681 acc:0.780439121756487\r\n",
      "curr: 1000 train loss: 0.507816023240091 acc:0.7232767232767233\r\n",
      "curr: 1500 train loss: 0.4965029141266781 acc:0.7321785476349101\r\n",
      "curr: 2000 train loss: 0.4879490206993782 acc:0.7341329335332334\r\n",
      "curr: 2500 train loss: 0.5023051107145148 acc:0.7297081167532987\r\n",
      "curr: 3000 train loss: 0.5106053801399834 acc:0.732755748083972\r\n",
      "curr: 3500 train loss: 0.5129807960472931 acc:0.7309340188517567\r\n",
      "curr: 4000 train loss: 0.5174213843620094 acc:0.7343164208947763\r\n",
      "curr: 4500 train loss: 0.5198741389487234 acc:0.7347256165296601\r\n",
      "curr: 5000 train loss: 0.5193508515037226 acc:0.737252549490102\r\n",
      "curr: 5500 train loss: 0.5192427491873959 acc:0.737684057444101\r\n",
      "curr: 6000 train loss: 0.5210940973397505 acc:0.7352107982003\r\n",
      "curr: 6500 train loss: 0.5167706632175201 acc:0.737117366558991\r\n",
      "curr: 7000 train loss: 0.516820793137367 acc:0.7363233823739466\r\n",
      "curr: 7500 train loss: 0.5203873241244313 acc:0.7339021463804826\r\n",
      "curr: 8000 train loss: 0.5193962775356296 acc:0.7349081364829396\r\n",
      "curr: 8500 train loss: 0.5206063856874135 acc:0.7347370897541465\r\n",
      "curr: 9000 train loss: 0.5199307001613852 acc:0.7354738362404177\r\n",
      "curr: 9500 train loss: 0.5208730751852381 acc:0.7352910219976845\r\n",
      "curr: 10000 train loss: 0.521625497116701 acc:0.7349265073492651\r\n",
      "curr: 10500 train loss: 0.5198111472889686 acc:0.7374535758499191\r\n",
      "curr: 11000 train loss: 0.5175505408294884 acc:0.7392055267702936\r\n",
      "curr: 11500 train loss: 0.5174314811439606 acc:0.7401095556908095\r\n",
      "curr: 12000 train loss: 0.5171922742827227 acc:0.7403549704191318\r\n",
      "curr: 12500 train loss: 0.5164068530386334 acc:0.7413806895448364\r\n",
      "curr: 13000 train loss: 0.516851308606083 acc:0.7407122529036227\r\n",
      "curr: 13500 train loss: 0.5160975553117342 acc:0.741870972520554\r\n",
      "curr: 14000 train loss: 0.5143520998232403 acc:0.7425183915434612\r\n",
      "curr: 14500 train loss: 0.5122557210780335 acc:0.7443624577615336\r\n",
      "curr: 15000 train loss: 0.511642877336595 acc:0.7454836344243717\r\n",
      "curr: 15500 train loss: 0.5129980688227946 acc:0.7449196826011225\r\n",
      "curr: 16000 train loss: 0.512403178277558 acc:0.7460783701018686\r\n",
      "curr: 16500 train loss: 0.511066930967213 acc:0.7466820192715593\r\n",
      "correct: 12607\r\n",
      "epochs 15 train loss: 0.5117740373039554 acc: 0.7464179988158673\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.4155281221016641 acc:0.810379241516966\r\n",
      "curr: 1000 train loss: 0.4884491050672042 acc:0.7352647352647352\r\n",
      "curr: 1500 train loss: 0.4820771625289698 acc:0.7388407728181212\r\n",
      "curr: 2000 train loss: 0.4725291365118027 acc:0.7416291854072964\r\n",
      "curr: 2500 train loss: 0.485368424802296 acc:0.7341063574570172\r\n",
      "curr: 3000 train loss: 0.4970078821050442 acc:0.7334221926024659\r\n",
      "curr: 3500 train loss: 0.5010769148838525 acc:0.7326478149100257\r\n",
      "curr: 4000 train loss: 0.505719713665765 acc:0.7353161709572607\r\n",
      "curr: 4500 train loss: 0.5089760267147236 acc:0.7376138635858698\r\n",
      "curr: 5000 train loss: 0.5089397121728567 acc:0.7396520695860828\r\n",
      "curr: 5500 train loss: 0.5087626491098604 acc:0.7400472641337938\r\n",
      "curr: 6000 train loss: 0.5117189718963165 acc:0.7365439093484419\r\n",
      "curr: 6500 train loss: 0.5080615606821061 acc:0.7389632364251654\r\n",
      "curr: 7000 train loss: 0.5084490317374639 acc:0.7380374232252536\r\n",
      "curr: 7500 train loss: 0.512334786271551 acc:0.7353686175176644\r\n",
      "curr: 8000 train loss: 0.5124052308109942 acc:0.735658042744657\r\n",
      "curr: 8500 train loss: 0.5136328123469669 acc:0.7361486883896012\r\n",
      "curr: 9000 train loss: 0.5135834980301872 acc:0.7369181202088657\r\n",
      "curr: 9500 train loss: 0.514847404266455 acc:0.73634354278497\r\n",
      "curr: 10000 train loss: 0.516310461061101 acc:0.7356264373562644\r\n",
      "curr: 10500 train loss: 0.5150022638440985 acc:0.7379297209789544\r\n",
      "curr: 11000 train loss: 0.5126186787772893 acc:0.7398418325606763\r\n",
      "curr: 11500 train loss: 0.5124270598665537 acc:0.7403704025736892\r\n",
      "curr: 12000 train loss: 0.5126219328184503 acc:0.7405216231980668\r\n",
      "curr: 12500 train loss: 0.512109900493522 acc:0.7417006639468843\r\n",
      "curr: 13000 train loss: 0.5126070836211591 acc:0.7407122529036227\r\n",
      "curr: 13500 train loss: 0.5115682035660368 acc:0.741796903933042\r\n",
      "curr: 14000 train loss: 0.5097263916983538 acc:0.7426612384829655\r\n",
      "curr: 14500 train loss: 0.5077783362102123 acc:0.7443624577615336\r\n",
      "curr: 15000 train loss: 0.5073654104155239 acc:0.7455502966468902\r\n",
      "curr: 15500 train loss: 0.5086965955097099 acc:0.7451132185020322\r\n",
      "curr: 16000 train loss: 0.5088151861681793 acc:0.7457033935379039\r\n",
      "curr: 16500 train loss: 0.5075327553897325 acc:0.7463790073328889\r\n",
      "correct: 12600\r\n",
      "epochs 16 train loss: 0.50828756972749 acc: 0.7460035523978685\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.4124740328929029 acc:0.7964071856287425\r\n",
      "curr: 1000 train loss: 0.47630260587882545 acc:0.7322677322677322\r\n",
      "curr: 1500 train loss: 0.46517435271685864 acc:0.7481678880746169\r\n",
      "curr: 2000 train loss: 0.4589718515147073 acc:0.7476261869065467\r\n",
      "curr: 2500 train loss: 0.47043877273895846 acc:0.7377049180327869\r\n",
      "curr: 3000 train loss: 0.482726022293649 acc:0.736754415194935\r\n",
      "curr: 3500 train loss: 0.4977573768207345 acc:0.7372179377320766\r\n",
      "curr: 4000 train loss: 0.5031316842240705 acc:0.7395651087228193\r\n",
      "curr: 4500 train loss: 0.5079229098552417 acc:0.7407242834925573\r\n",
      "curr: 5000 train loss: 0.5077861703796124 acc:0.7414517096580684\r\n",
      "curr: 5500 train loss: 0.5078636920935077 acc:0.742592255953463\r\n",
      "curr: 6000 train loss: 0.5109176995988204 acc:0.7392101316447259\r\n",
      "curr: 6500 train loss: 0.5076151838704203 acc:0.7406552838024919\r\n",
      "curr: 7000 train loss: 0.5079617993153374 acc:0.7400371375517784\r\n",
      "curr: 7500 train loss: 0.5111303934884732 acc:0.7383015597920277\r\n",
      "curr: 8000 train loss: 0.5104230818405552 acc:0.7387826521684789\r\n",
      "curr: 8500 train loss: 0.511916871549836 acc:0.7382660863427832\r\n",
      "curr: 9000 train loss: 0.511647239515747 acc:0.7389178980113321\r\n",
      "curr: 9500 train loss: 0.5129300661792503 acc:0.7373960635722555\r\n",
      "curr: 10000 train loss: 0.5145895557818096 acc:0.7363263673632636\r\n",
      "curr: 10500 train loss: 0.5129749562026379 acc:0.7392629273402533\r\n",
      "curr: 11000 train loss: 0.5101841852915074 acc:0.7412962457958368\r\n",
      "curr: 11500 train loss: 0.5099928155889278 acc:0.7424571776367273\r\n",
      "curr: 12000 train loss: 0.5100648579527878 acc:0.7425214565452879\r\n",
      "curr: 12500 train loss: 0.509968396667398 acc:0.7433005359571234\r\n",
      "curr: 13000 train loss: 0.5101534229347496 acc:0.7430966848703946\r\n",
      "curr: 13500 train loss: 0.5092735982684959 acc:0.7446115102584994\r\n",
      "curr: 14000 train loss: 0.5075867857010861 acc:0.7458038711520606\r\n",
      "curr: 14500 train loss: 0.5057952438752862 acc:0.7470519274532791\r\n",
      "curr: 15000 train loss: 0.5051798259477177 acc:0.7484167722151857\r\n",
      "curr: 15500 train loss: 0.5062294254690377 acc:0.7476291852138571\r\n",
      "curr: 16000 train loss: 0.5057688751070507 acc:0.7483282294856571\r\n",
      "curr: 16500 train loss: 0.5042465576091385 acc:0.7490455123931883\r\n",
      "correct: 12647\r\n",
      "epochs 17 train loss: 0.5046154126444442 acc: 0.7487862640615749\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.40150516153265897 acc:0.8063872255489022\r\n",
      "curr: 1000 train loss: 0.46967375002007633 acc:0.7412587412587412\r\n",
      "curr: 1500 train loss: 0.4602294893407222 acc:0.7514990006662225\r\n",
      "curr: 2000 train loss: 0.4564743468209479 acc:0.7526236881559221\r\n",
      "curr: 2500 train loss: 0.4780807900901974 acc:0.7421031587365055\r\n",
      "curr: 3000 train loss: 0.4891262485306353 acc:0.7387537487504166\r\n",
      "curr: 3500 train loss: 0.49306207519443496 acc:0.7375035704084547\r\n",
      "curr: 4000 train loss: 0.4986260921741483 acc:0.7393151712071983\r\n",
      "curr: 4500 train loss: 0.5040868984719767 acc:0.7411686291935126\r\n",
      "curr: 5000 train loss: 0.5047155203459065 acc:0.7400519896020796\r\n",
      "curr: 5500 train loss: 0.504691502385594 acc:0.7402290492637702\r\n",
      "curr: 6000 train loss: 0.507037877162251 acc:0.7373771038160306\r\n",
      "curr: 6500 train loss: 0.5041359430214257 acc:0.739424703891709\r\n",
      "curr: 7000 train loss: 0.5054527623019371 acc:0.7390372803885159\r\n",
      "curr: 7500 train loss: 0.5097400361324683 acc:0.7363018264231436\r\n",
      "curr: 8000 train loss: 0.5091449065282367 acc:0.7375328083989501\r\n",
      "curr: 8500 train loss: 0.5104724210929881 acc:0.7367368544877073\r\n",
      "curr: 9000 train loss: 0.5101577089210165 acc:0.7378069103432952\r\n",
      "curr: 9500 train loss: 0.5115067919081532 acc:0.7361330386275129\r\n",
      "curr: 10000 train loss: 0.5131398337872013 acc:0.736026397360264\r\n",
      "curr: 10500 train loss: 0.5118101942244896 acc:0.7377392629273403\r\n",
      "curr: 11000 train loss: 0.509305804026489 acc:0.7397509317334787\r\n",
      "curr: 11500 train loss: 0.5091809675629974 acc:0.740718198417529\r\n",
      "curr: 12000 train loss: 0.5088474318358718 acc:0.7414382134822098\r\n",
      "curr: 12500 train loss: 0.5082188126267951 acc:0.74234061275098\r\n",
      "curr: 13000 train loss: 0.5083286345315146 acc:0.7420198446273364\r\n",
      "curr: 13500 train loss: 0.5073335312671737 acc:0.7436486186208429\r\n",
      "curr: 14000 train loss: 0.5060669675075727 acc:0.7449467895150347\r\n",
      "curr: 14500 train loss: 0.504294324543328 acc:0.746707123646645\r\n",
      "curr: 15000 train loss: 0.503865845605235 acc:0.7470168655422972\r\n",
      "curr: 15500 train loss: 0.5051306529586226 acc:0.7462099219405199\r\n",
      "curr: 16000 train loss: 0.5045646182805341 acc:0.7466408349478157\r\n",
      "curr: 16500 train loss: 0.5035086875522171 acc:0.7472880431489001\r\n",
      "correct: 12613\r\n",
      "epochs 18 train loss: 0.505499824224406 acc: 0.7467732386027235\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3952502893015704 acc:0.812375249500998\r\n",
      "curr: 1000 train loss: 0.46595472572000085 acc:0.7412587412587412\r\n",
      "curr: 1500 train loss: 0.4582423301935134 acc:0.748834110592938\r\n",
      "curr: 2000 train loss: 0.45008985765205295 acc:0.7531234382808596\r\n",
      "curr: 2500 train loss: 0.4634604838810565 acc:0.743702518992403\r\n",
      "curr: 3000 train loss: 0.47754840528628667 acc:0.7404198600466512\r\n",
      "curr: 3500 train loss: 0.482749014964779 acc:0.7397886318194802\r\n",
      "curr: 4000 train loss: 0.4887661539505502 acc:0.7418145463634092\r\n",
      "curr: 4500 train loss: 0.4924319495761828 acc:0.7433903576982893\r\n",
      "curr: 5000 train loss: 0.4955963992961104 acc:0.7436512697460508\r\n",
      "curr: 5500 train loss: 0.4974942984721439 acc:0.7429558262134157\r\n",
      "curr: 6000 train loss: 0.5018581014186877 acc:0.7393767705382436\r\n",
      "curr: 6500 train loss: 0.4995156989241539 acc:0.7414243962467313\r\n",
      "curr: 7000 train loss: 0.5005713358188033 acc:0.7417511784030852\r\n",
      "curr: 7500 train loss: 0.5045039546107747 acc:0.7388348220237302\r\n",
      "curr: 8000 train loss: 0.5044902680122588 acc:0.7390326209223848\r\n",
      "curr: 8500 train loss: 0.5060184901975397 acc:0.7395600517586166\r\n",
      "curr: 9000 train loss: 0.5058017525485727 acc:0.7405843795133874\r\n",
      "curr: 9500 train loss: 0.5068004794473727 acc:0.7400273655404694\r\n",
      "curr: 10000 train loss: 0.5077053005540355 acc:0.7398260173982601\r\n",
      "curr: 10500 train loss: 0.505668117312392 acc:0.7421197981144653\r\n",
      "curr: 11000 train loss: 0.5032113950118557 acc:0.7441141714389601\r\n",
      "curr: 11500 train loss: 0.5031408122256017 acc:0.7453264933484045\r\n",
      "curr: 12000 train loss: 0.5034036990112558 acc:0.745604532955587\r\n",
      "curr: 12500 train loss: 0.5030195909002655 acc:0.7470602351811855\r\n",
      "curr: 13000 train loss: 0.5032969575485872 acc:0.7466348742404431\r\n",
      "curr: 13500 train loss: 0.5022858760502306 acc:0.748018665284053\r\n",
      "curr: 14000 train loss: 0.5006593891115118 acc:0.7495893150489251\r\n",
      "curr: 14500 train loss: 0.49884482358167864 acc:0.7508447693262533\r\n",
      "curr: 15000 train loss: 0.4985644479778353 acc:0.7514165722285181\r\n",
      "curr: 15500 train loss: 0.4999267091646122 acc:0.7505967356944713\r\n",
      "curr: 16000 train loss: 0.49990787094920996 acc:0.7510780576213987\r\n",
      "curr: 16500 train loss: 0.49854661701525244 acc:0.7514696079025514\r\n",
      "correct: 12675\r\n",
      "epochs 19 train loss: 0.4997158644526257 acc: 0.7504440497335702\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.40065554296936323 acc:0.8023952095808383\r\n",
      "curr: 1000 train loss: 0.4723776993956207 acc:0.7332667332667333\r\n",
      "curr: 1500 train loss: 0.45996734373510073 acc:0.7421718854097269\r\n",
      "curr: 2000 train loss: 0.4481249748878716 acc:0.7501249375312344\r\n",
      "curr: 2500 train loss: 0.4575937161532381 acc:0.7429028388644542\r\n",
      "curr: 3000 train loss: 0.47130722821194454 acc:0.7417527490836388\r\n",
      "curr: 3500 train loss: 0.4786204650451399 acc:0.7389317337903456\r\n",
      "curr: 4000 train loss: 0.4870534950090005 acc:0.7385653586603349\r\n",
      "curr: 4500 train loss: 0.49342576797872206 acc:0.7409464563430349\r\n",
      "curr: 5000 train loss: 0.4947077590954044 acc:0.74125174965007\r\n",
      "curr: 5500 train loss: 0.4962380550225069 acc:0.742046900563534\r\n",
      "curr: 6000 train loss: 0.49923937339220864 acc:0.7397100483252791\r\n",
      "curr: 6500 train loss: 0.49600793396564646 acc:0.7418858637132749\r\n",
      "curr: 7000 train loss: 0.49736433669377167 acc:0.7416083416654764\r\n",
      "curr: 7500 train loss: 0.5014562359220041 acc:0.7401679776029862\r\n",
      "curr: 8000 train loss: 0.5016179018141305 acc:0.7400324959380078\r\n",
      "curr: 8500 train loss: 0.5036773193853481 acc:0.739207152099753\r\n",
      "curr: 9000 train loss: 0.5035235790777046 acc:0.7398066881457616\r\n",
      "curr: 9500 train loss: 0.5043231994074869 acc:0.739185348910641\r\n",
      "curr: 10000 train loss: 0.5097328880322033 acc:0.7390260973902609\r\n",
      "curr: 10500 train loss: 0.5086558459851784 acc:0.7411675078563946\r\n",
      "curr: 11000 train loss: 0.5060381355427896 acc:0.7432960639941824\r\n",
      "curr: 11500 train loss: 0.5058427235799668 acc:0.7441961568559256\r\n",
      "curr: 12000 train loss: 0.5058070262941001 acc:0.7444379635030414\r\n",
      "curr: 12500 train loss: 0.5054613757974044 acc:0.7453003759699224\r\n",
      "curr: 13000 train loss: 0.5053923847958479 acc:0.7447888623952004\r\n",
      "curr: 13500 train loss: 0.5045894237637363 acc:0.7457966076586919\r\n",
      "curr: 14000 train loss: 0.5029588427827701 acc:0.7468037997285908\r\n",
      "curr: 14500 train loss: 0.5010378663054941 acc:0.7482932211571616\r\n",
      "curr: 15000 train loss: 0.5002460939160266 acc:0.7494167055529631\r\n",
      "curr: 15500 train loss: 0.5013806961895702 acc:0.7484033288174956\r\n",
      "curr: 16000 train loss: 0.5014732204752376 acc:0.7490781826135866\r\n",
      "curr: 16500 train loss: 0.50023954811077 acc:0.7497727410459972\r\n",
      "correct: 12659\r\n",
      "epochs 20 train loss: 0.5008118063425783 acc: 0.7494967436352872\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.38543690786247026 acc:0.8263473053892215\r\n",
      "curr: 1000 train loss: 0.47444824021343196 acc:0.7402597402597403\r\n",
      "curr: 1500 train loss: 0.4626383045564655 acc:0.7481678880746169\r\n",
      "curr: 2000 train loss: 0.4487766286143484 acc:0.7521239380309845\r\n",
      "curr: 2500 train loss: 0.4799617319825634 acc:0.7409036385445822\r\n",
      "curr: 3000 train loss: 0.4915143686981098 acc:0.7387537487504166\r\n",
      "curr: 3500 train loss: 0.49675563086665103 acc:0.7377892030848329\r\n",
      "curr: 4000 train loss: 0.5007594351343964 acc:0.7405648587853036\r\n",
      "curr: 4500 train loss: 0.502097057571983 acc:0.7429460119973339\r\n",
      "curr: 5000 train loss: 0.5014945240732318 acc:0.7446510697860428\r\n",
      "curr: 5500 train loss: 0.5023828317985042 acc:0.7447736775131795\r\n",
      "curr: 6000 train loss: 0.5043607140554442 acc:0.7428761873021164\r\n",
      "curr: 6500 train loss: 0.5018491911369992 acc:0.7448084910013844\r\n",
      "curr: 7000 train loss: 0.5020370533370875 acc:0.7446079131552635\r\n",
      "curr: 7500 train loss: 0.5054228972388132 acc:0.7421677109718704\r\n",
      "curr: 8000 train loss: 0.5052074142063321 acc:0.7422822147231596\r\n",
      "curr: 8500 train loss: 0.5065904037638576 acc:0.7421479825902835\r\n",
      "curr: 9000 train loss: 0.5060735763978537 acc:0.743250749916676\r\n",
      "curr: 9500 train loss: 0.5066888558478618 acc:0.7428691716661404\r\n",
      "curr: 10000 train loss: 0.5077852373222385 acc:0.7424257574242575\r\n",
      "curr: 10500 train loss: 0.506511207546632 acc:0.7447862108370631\r\n",
      "curr: 11000 train loss: 0.5038178069682958 acc:0.7471138987364785\r\n",
      "curr: 11500 train loss: 0.5042678100315049 acc:0.7475002173724024\r\n",
      "curr: 12000 train loss: 0.5044213296104442 acc:0.747437713523873\r\n",
      "curr: 12500 train loss: 0.5045839301886297 acc:0.748100151987841\r\n",
      "curr: 13000 train loss: 0.5044106158027513 acc:0.7469425428813168\r\n",
      "curr: 13500 train loss: 0.5030074343899928 acc:0.7483890082216132\r\n",
      "curr: 14000 train loss: 0.5012949759989632 acc:0.7497321619884294\r\n",
      "curr: 14500 train loss: 0.4993223498728705 acc:0.7513964554168678\r\n",
      "curr: 15000 train loss: 0.4986485325060947 acc:0.7520165322311846\r\n",
      "curr: 15500 train loss: 0.4998248977168033 acc:0.75130636733114\r\n",
      "curr: 16000 train loss: 0.4998669296434379 acc:0.752265483407287\r\n",
      "curr: 16500 train loss: 0.49847615674638635 acc:0.752742258044967\r\n",
      "correct: 12710\r\n",
      "epochs 21 train loss: 0.49927768676622003 acc: 0.7525162818235642\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3799169787824953 acc:0.8323353293413174\r\n",
      "curr: 1000 train loss: 0.46500901618070156 acc:0.7432567432567433\r\n",
      "curr: 1500 train loss: 0.452152729815267 acc:0.7528314457028648\r\n",
      "curr: 2000 train loss: 0.4410588858695026 acc:0.7576211894052973\r\n",
      "curr: 2500 train loss: 0.4542483897532307 acc:0.7465013994402239\r\n",
      "curr: 3000 train loss: 0.46999479594768484 acc:0.7430856381206264\r\n",
      "curr: 3500 train loss: 0.4764618113399367 acc:0.7429305912596401\r\n",
      "curr: 4000 train loss: 0.48295179011785583 acc:0.7423144213946513\r\n",
      "curr: 4500 train loss: 0.486309337748013 acc:0.743612530548767\r\n",
      "curr: 5000 train loss: 0.48783462689657225 acc:0.7448510297940412\r\n",
      "curr: 5500 train loss: 0.49004600955284106 acc:0.7449554626431558\r\n",
      "curr: 6000 train loss: 0.49652609350927945 acc:0.7418763539410098\r\n",
      "curr: 6500 train loss: 0.49373594215965805 acc:0.7445008460236887\r\n",
      "curr: 7000 train loss: 0.4950854604959424 acc:0.7440365662048278\r\n",
      "curr: 7500 train loss: 0.49926764091431564 acc:0.7417677642980935\r\n",
      "curr: 8000 train loss: 0.4993155542439168 acc:0.7427821522309711\r\n",
      "curr: 8500 train loss: 0.501174875747347 acc:0.7425008822491471\r\n",
      "curr: 9000 train loss: 0.5009664019396903 acc:0.7431396511498722\r\n",
      "curr: 9500 train loss: 0.5020614138284238 acc:0.7423429112724976\r\n",
      "curr: 10000 train loss: 0.5034677669513873 acc:0.7422257774222578\r\n",
      "curr: 10500 train loss: 0.5027339926506803 acc:0.7441196076564137\r\n",
      "curr: 11000 train loss: 0.5000228388755326 acc:0.7462048904645032\r\n",
      "curr: 11500 train loss: 0.5003053273690723 acc:0.7472393704895226\r\n",
      "curr: 12000 train loss: 0.5005939457230494 acc:0.7473543871344055\r\n",
      "curr: 12500 train loss: 0.5004373377631866 acc:0.748100151987841\r\n",
      "curr: 13000 train loss: 0.5001326923786729 acc:0.747327128682409\r\n",
      "curr: 13500 train loss: 0.49895421224485126 acc:0.7483890082216132\r\n",
      "curr: 14000 train loss: 0.4969821028890763 acc:0.7496607385186772\r\n",
      "curr: 14500 train loss: 0.49517356994098977 acc:0.7512585338942142\r\n",
      "curr: 15000 train loss: 0.49437849327862543 acc:0.7520831944537031\r\n",
      "curr: 15500 train loss: 0.4958214154696556 acc:0.7512418553641701\r\n",
      "curr: 16000 train loss: 0.4955375550342202 acc:0.7520779951253047\r\n",
      "curr: 16500 train loss: 0.49404690011778996 acc:0.7524392461062965\r\n",
      "correct: 12698\r\n",
      "epochs 22 train loss: 0.49510991090910556 acc: 0.7518058022498519\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3851218501116886 acc:0.8243512974051896\r\n",
      "curr: 1000 train loss: 0.4664879270577216 acc:0.7382617382617382\r\n",
      "curr: 1500 train loss: 0.4549971170542822 acc:0.7534976682211859\r\n",
      "curr: 2000 train loss: 0.4475163088189354 acc:0.760119940029985\r\n",
      "curr: 2500 train loss: 0.4601258821745928 acc:0.7516993202718912\r\n",
      "curr: 3000 train loss: 0.4748582133619807 acc:0.749083638787071\r\n",
      "curr: 3500 train loss: 0.4806714161407582 acc:0.7452156526706655\r\n",
      "curr: 4000 train loss: 0.48575646243071935 acc:0.7470632341914522\r\n",
      "curr: 4500 train loss: 0.4887317075362936 acc:0.7471672961564096\r\n",
      "curr: 5000 train loss: 0.4892670345791519 acc:0.7484503099380124\r\n",
      "curr: 5500 train loss: 0.4917501303608326 acc:0.748045809852754\r\n",
      "curr: 6000 train loss: 0.49565013137554115 acc:0.7458756873854357\r\n",
      "curr: 6500 train loss: 0.4930457731198729 acc:0.7472696508229503\r\n",
      "curr: 7000 train loss: 0.49355612505030366 acc:0.7457506070561348\r\n",
      "curr: 7500 train loss: 0.4971784954771706 acc:0.743367550993201\r\n",
      "curr: 8000 train loss: 0.49697332754382584 acc:0.745031871016123\r\n",
      "curr: 8500 train loss: 0.4993976775970295 acc:0.7442653805434655\r\n",
      "curr: 9000 train loss: 0.49917124800000606 acc:0.7452505277191424\r\n",
      "curr: 9500 train loss: 0.5003532515685061 acc:0.7444479528470688\r\n",
      "curr: 10000 train loss: 0.5065877134615585 acc:0.7436256374362564\r\n",
      "curr: 10500 train loss: 0.5050465233753699 acc:0.746024188172555\r\n",
      "curr: 11000 train loss: 0.502233143014846 acc:0.7482047086628488\r\n",
      "curr: 11500 train loss: 0.5033573912826674 acc:0.7493261455525606\r\n",
      "curr: 12000 train loss: 0.503537962137797 acc:0.749270894092159\r\n",
      "curr: 12500 train loss: 0.5029742416417189 acc:0.7503399728021758\r\n",
      "curr: 13000 train loss: 0.502702166398345 acc:0.7497115606491809\r\n",
      "curr: 13500 train loss: 0.5016187397467202 acc:0.7508332716095104\r\n",
      "curr: 14000 train loss: 0.4997750230072737 acc:0.7521605599600029\r\n",
      "curr: 14500 train loss: 0.4979203393044941 acc:0.7537411213019791\r\n",
      "curr: 15000 train loss: 0.49713638985998637 acc:0.754483034464369\r\n",
      "curr: 15500 train loss: 0.4983631057567208 acc:0.7540803819108445\r\n",
      "curr: 16000 train loss: 0.4982989215620523 acc:0.7545778388850697\r\n",
      "curr: 16500 train loss: 0.49694193763738714 acc:0.7552269559420641\r\n",
      "correct: 12750\r\n",
      "epochs 23 train loss: 0.49787125163752993 acc: 0.7548845470692718\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.4037333580259995 acc:0.8243512974051896\r\n",
      "curr: 1000 train loss: 0.47236540049828174 acc:0.7452547452547452\r\n",
      "curr: 1500 train loss: 0.45774672559643015 acc:0.7501665556295802\r\n",
      "curr: 2000 train loss: 0.44399107369812024 acc:0.760119940029985\r\n",
      "curr: 2500 train loss: 0.4824547018711189 acc:0.7516993202718912\r\n",
      "curr: 3000 train loss: 0.492291587325485 acc:0.7460846384538488\r\n",
      "curr: 3500 train loss: 0.4956064247741464 acc:0.744358754641531\r\n",
      "curr: 4000 train loss: 0.5009285719546619 acc:0.7460634841289677\r\n",
      "curr: 4500 train loss: 0.5045294332713965 acc:0.7473894690068874\r\n",
      "curr: 5000 train loss: 0.503765762616718 acc:0.748250349930014\r\n",
      "curr: 5500 train loss: 0.5058235081243582 acc:0.7484093801127067\r\n",
      "curr: 6000 train loss: 0.5080471971724523 acc:0.7452091318113647\r\n",
      "curr: 6500 train loss: 0.5046349265899956 acc:0.746500538378711\r\n",
      "curr: 7000 train loss: 0.5049027894794086 acc:0.7463219540065705\r\n",
      "curr: 7500 train loss: 0.5077883865999269 acc:0.7439008132249033\r\n",
      "curr: 8000 train loss: 0.5069063636866585 acc:0.745031871016123\r\n",
      "curr: 8500 train loss: 0.5081068192306866 acc:0.7443830137630867\r\n",
      "curr: 9000 train loss: 0.5072348627436105 acc:0.7451394289523386\r\n",
      "curr: 9500 train loss: 0.507730642270019 acc:0.744868961161983\r\n",
      "curr: 10000 train loss: 0.513283998567914 acc:0.7439256074392561\r\n",
      "curr: 10500 train loss: 0.5114665319143689 acc:0.7463098752499762\r\n",
      "curr: 11000 train loss: 0.5084330089618929 acc:0.748568311971639\r\n",
      "curr: 11500 train loss: 0.5079814238067704 acc:0.7496739413964003\r\n",
      "curr: 12000 train loss: 0.5078863839421718 acc:0.7496041996500291\r\n",
      "curr: 12500 train loss: 0.5073891310016491 acc:0.7500999920006399\r\n",
      "curr: 13000 train loss: 0.5065458392817114 acc:0.7497884778093993\r\n",
      "curr: 13500 train loss: 0.505143820835355 acc:0.7510554773720465\r\n",
      "curr: 14000 train loss: 0.5031350700811131 acc:0.7521605599600029\r\n",
      "curr: 14500 train loss: 0.5008863393417146 acc:0.75415488586994\r\n",
      "curr: 15000 train loss: 0.5001935993320726 acc:0.7548163455769615\r\n",
      "curr: 15500 train loss: 0.50088911856157 acc:0.7544029417456938\r\n",
      "curr: 16000 train loss: 0.5007521228272062 acc:0.7550778076370227\r\n",
      "curr: 16500 train loss: 0.49926696047071417 acc:0.7554693654930005\r\n",
      "correct: 12746\r\n",
      "epochs 24 train loss: 0.5002145135313762 acc: 0.754647720544701\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.37852709554927744 acc:0.8183632734530938\r\n",
      "curr: 1000 train loss: 0.46017389367626427 acc:0.7512487512487512\r\n",
      "curr: 1500 train loss: 0.4495521797316453 acc:0.7574950033311126\r\n",
      "curr: 2000 train loss: 0.44010734335345286 acc:0.7636181909045477\r\n",
      "curr: 2500 train loss: 0.45000013702188396 acc:0.7524990003998401\r\n",
      "curr: 3000 train loss: 0.4681744113868705 acc:0.748750416527824\r\n",
      "curr: 3500 train loss: 0.4743822566265491 acc:0.7475007140816909\r\n",
      "curr: 4000 train loss: 0.4816105756040027 acc:0.7480629842539365\r\n",
      "curr: 4500 train loss: 0.48749613335886577 acc:0.7476116418573651\r\n",
      "curr: 5000 train loss: 0.48819894220855825 acc:0.7484503099380124\r\n",
      "curr: 5500 train loss: 0.49059272739983506 acc:0.7484093801127067\r\n",
      "curr: 6000 train loss: 0.4953404419098733 acc:0.7458756873854357\r\n",
      "curr: 6500 train loss: 0.4929070913071719 acc:0.7471158283341024\r\n",
      "curr: 7000 train loss: 0.49384102416432163 acc:0.7461791172689616\r\n",
      "curr: 7500 train loss: 0.49808425496791 acc:0.7437674976669777\r\n",
      "curr: 8000 train loss: 0.4977035590982553 acc:0.7444069491313586\r\n",
      "curr: 8500 train loss: 0.4998386802198149 acc:0.744030114104223\r\n",
      "curr: 9000 train loss: 0.4993948353279169 acc:0.7450283301855349\r\n",
      "curr: 9500 train loss: 0.5005682480200144 acc:0.7437111882959688\r\n",
      "curr: 10000 train loss: 0.5030638105486658 acc:0.7436256374362564\r\n",
      "curr: 10500 train loss: 0.5024205960898971 acc:0.7458337301209409\r\n",
      "curr: 11000 train loss: 0.5001447985516401 acc:0.7476593036996637\r\n",
      "curr: 11500 train loss: 0.49905243488188933 acc:0.7484566559429615\r\n",
      "curr: 12000 train loss: 0.4988535604862598 acc:0.7484376301974835\r\n",
      "curr: 12500 train loss: 0.4986853188391613 acc:0.7493800495960323\r\n",
      "curr: 13000 train loss: 0.4984733064766027 acc:0.7487116375663411\r\n",
      "curr: 13500 train loss: 0.49694177509964405 acc:0.7502407229094141\r\n",
      "curr: 14000 train loss: 0.495267709379922 acc:0.7511606313834726\r\n",
      "curr: 14500 train loss: 0.49349277465369484 acc:0.7528446314047307\r\n",
      "curr: 15000 train loss: 0.4931056219991835 acc:0.7537497500166656\r\n",
      "curr: 15500 train loss: 0.49443700783380845 acc:0.7531772143732662\r\n",
      "curr: 16000 train loss: 0.4943908506821571 acc:0.7538278857571402\r\n",
      "curr: 16500 train loss: 0.49314472983758334 acc:0.7541967153505849\r\n",
      "correct: 12729\r\n",
      "epochs 25 train loss: 0.49406011842104886 acc: 0.7536412078152753\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.36606391886486916 acc:0.8323353293413174\r\n",
      "curr: 1000 train loss: 0.4472758010345307 acc:0.7572427572427572\r\n",
      "curr: 1500 train loss: 0.44097527283502963 acc:0.7628247834776816\r\n",
      "curr: 2000 train loss: 0.43162867408195793 acc:0.769615192403798\r\n",
      "curr: 2500 train loss: 0.4709475244868569 acc:0.7588964414234306\r\n",
      "curr: 3000 train loss: 0.481516067973933 acc:0.7554148617127624\r\n",
      "curr: 3500 train loss: 0.4856195035757666 acc:0.7529277349328763\r\n",
      "curr: 4000 train loss: 0.49021304696515716 acc:0.7510622344413896\r\n",
      "curr: 4500 train loss: 0.4944955931080434 acc:0.7529437902688292\r\n",
      "curr: 5000 train loss: 0.4951334911254105 acc:0.7518496300739852\r\n",
      "curr: 5500 train loss: 0.4971927776742338 acc:0.7514997273223051\r\n",
      "curr: 6000 train loss: 0.5013301121018481 acc:0.7488751874687553\r\n",
      "curr: 6500 train loss: 0.4978831394989637 acc:0.7514228580218428\r\n",
      "curr: 7000 train loss: 0.4987215132655541 acc:0.7500357091844022\r\n",
      "curr: 7500 train loss: 0.5022937223768856 acc:0.7481669110785228\r\n",
      "curr: 8000 train loss: 0.502202750854486 acc:0.7486564179477565\r\n",
      "curr: 8500 train loss: 0.5035671918424581 acc:0.7486178096694507\r\n",
      "curr: 9000 train loss: 0.5029247513850551 acc:0.7488056882568603\r\n",
      "curr: 9500 train loss: 0.5034836787176961 acc:0.7471845068940112\r\n",
      "curr: 10000 train loss: 0.5067657582897882 acc:0.7464253574642535\r\n",
      "curr: 10500 train loss: 0.5054025053668769 acc:0.7486906008951528\r\n",
      "curr: 11000 train loss: 0.5029160529077071 acc:0.7506590309971821\r\n",
      "curr: 11500 train loss: 0.5029880507730268 acc:0.7514998695765586\r\n",
      "curr: 12000 train loss: 0.5031571961537273 acc:0.7511040746604449\r\n",
      "curr: 12500 train loss: 0.5028515461116962 acc:0.7514598832093432\r\n",
      "curr: 13000 train loss: 0.5023449848477559 acc:0.7510191523728944\r\n",
      "curr: 13500 train loss: 0.5007541589049115 acc:0.752092437597215\r\n",
      "curr: 14000 train loss: 0.4989354263182127 acc:0.7536604528247982\r\n",
      "curr: 14500 train loss: 0.49706013315470216 acc:0.7550513757671885\r\n",
      "curr: 15000 train loss: 0.49640741331503374 acc:0.755282981134591\r\n",
      "curr: 15500 train loss: 0.49728727403464046 acc:0.7544674537126637\r\n",
      "curr: 16000 train loss: 0.49744315204465134 acc:0.7550153115430286\r\n",
      "curr: 16500 train loss: 0.496080345760575 acc:0.7552269559420641\r\n",
      "correct: 12746\r\n",
      "epochs 26 train loss: 0.4973964145763075 acc: 0.754647720544701\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3834141569531303 acc:0.8263473053892215\r\n",
      "curr: 1000 train loss: 0.45443520577590957 acc:0.7452547452547452\r\n",
      "curr: 1500 train loss: 0.44243608034749715 acc:0.7548301132578281\r\n",
      "curr: 2000 train loss: 0.43144300165447036 acc:0.7606196901549226\r\n",
      "curr: 2500 train loss: 0.4471137552534458 acc:0.7508996401439424\r\n",
      "curr: 3000 train loss: 0.4629046868523464 acc:0.7460846384538488\r\n",
      "curr: 3500 train loss: 0.4703150172695571 acc:0.7457869180234219\r\n",
      "curr: 4000 train loss: 0.47730138705384595 acc:0.7463134216445888\r\n",
      "curr: 4500 train loss: 0.48249068846392035 acc:0.7498333703621417\r\n",
      "curr: 5000 train loss: 0.4845764295899843 acc:0.7490501899620076\r\n",
      "curr: 5500 train loss: 0.4881363946511922 acc:0.7487729503726596\r\n",
      "curr: 6000 train loss: 0.49335876277331 acc:0.745709048491918\r\n",
      "curr: 6500 train loss: 0.4904203849515267 acc:0.7471158283341024\r\n",
      "curr: 7000 train loss: 0.4908449195791953 acc:0.7474646479074418\r\n",
      "curr: 7500 train loss: 0.4941179819382236 acc:0.7461671777096387\r\n",
      "curr: 8000 train loss: 0.4945995258647394 acc:0.7467816522934633\r\n",
      "curr: 8500 train loss: 0.49619629118798414 acc:0.7466180449358899\r\n",
      "curr: 9000 train loss: 0.4964086171095121 acc:0.7469170092211976\r\n",
      "curr: 9500 train loss: 0.49703940858047924 acc:0.7462372381854542\r\n",
      "curr: 10000 train loss: 0.501053042286246 acc:0.746025397460254\r\n",
      "curr: 10500 train loss: 0.5004879848348578 acc:0.7487858299209599\r\n",
      "curr: 11000 train loss: 0.49723127188249266 acc:0.7512953367875648\r\n",
      "curr: 11500 train loss: 0.4973494306263004 acc:0.7525432571080776\r\n",
      "curr: 12000 train loss: 0.49735472623543536 acc:0.7522706441129906\r\n",
      "curr: 12500 train loss: 0.49759635155911064 acc:0.7524998000159987\r\n",
      "curr: 13000 train loss: 0.4974465163972655 acc:0.751634489654642\r\n",
      "curr: 13500 train loss: 0.49647088293703323 acc:0.7527590548848233\r\n",
      "curr: 14000 train loss: 0.4946121791557761 acc:0.7538032997643026\r\n",
      "curr: 14500 train loss: 0.49285478194020116 acc:0.7552582580511689\r\n",
      "curr: 15000 train loss: 0.49196257649758973 acc:0.755816278914739\r\n",
      "curr: 15500 train loss: 0.49326194481588087 acc:0.7547900135475131\r\n",
      "curr: 16000 train loss: 0.4930990860350327 acc:0.7555777763889757\r\n",
      "curr: 16500 train loss: 0.49190974469256216 acc:0.7559541845948731\r\n",
      "correct: 12765\r\n",
      "epochs 27 train loss: 0.492349088433701 acc: 0.7557726465364121\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3596518208389475 acc:0.8363273453093812\r\n",
      "curr: 1000 train loss: 0.45139074761754855 acc:0.7602397602397603\r\n",
      "curr: 1500 train loss: 0.44323204540466743 acc:0.7661558960692871\r\n",
      "curr: 2000 train loss: 0.4326186787216612 acc:0.7721139430284858\r\n",
      "curr: 2500 train loss: 0.46614348796935634 acc:0.7616953218712516\r\n",
      "curr: 3000 train loss: 0.47964890559957235 acc:0.7557480839720093\r\n",
      "curr: 3500 train loss: 0.4844716951108775 acc:0.7526421022564982\r\n",
      "curr: 4000 train loss: 0.48827519999590624 acc:0.7530617345663584\r\n",
      "curr: 4500 train loss: 0.4929288080547291 acc:0.7527216174183515\r\n",
      "curr: 5000 train loss: 0.4930116222469686 acc:0.7534493101379725\r\n",
      "curr: 5500 train loss: 0.49466367888023005 acc:0.7522268678422105\r\n",
      "curr: 6000 train loss: 0.500920536985645 acc:0.7478753541076487\r\n",
      "curr: 6500 train loss: 0.497677629903341 acc:0.7491155206891248\r\n",
      "curr: 7000 train loss: 0.4981649880503669 acc:0.7476074846450507\r\n",
      "curr: 7500 train loss: 0.5012122586419672 acc:0.7456339154779362\r\n",
      "curr: 8000 train loss: 0.5010726295522311 acc:0.7467816522934633\r\n",
      "curr: 8500 train loss: 0.502700204178742 acc:0.7462651452770263\r\n",
      "curr: 9000 train loss: 0.5026333692869913 acc:0.7465837129207866\r\n",
      "curr: 9500 train loss: 0.5028691371709912 acc:0.7466582465003684\r\n",
      "curr: 10000 train loss: 0.5037032431641896 acc:0.7467253274672533\r\n",
      "curr: 10500 train loss: 0.502946423047899 acc:0.7490715169983811\r\n",
      "curr: 11000 train loss: 0.49981053423432237 acc:0.7510226343059722\r\n",
      "curr: 11500 train loss: 0.4995285870518222 acc:0.7525432571080776\r\n",
      "curr: 12000 train loss: 0.4998209763984817 acc:0.7526872760603283\r\n",
      "curr: 12500 train loss: 0.4993539702540168 acc:0.7532997360211183\r\n",
      "curr: 13000 train loss: 0.4992670484218995 acc:0.7525574955772633\r\n",
      "curr: 13500 train loss: 0.497697856308473 acc:0.7537960151099918\r\n",
      "curr: 14000 train loss: 0.49569121712398506 acc:0.754874651810585\r\n",
      "curr: 14500 train loss: 0.4937724964523205 acc:0.756637473277705\r\n",
      "curr: 15000 train loss: 0.49292042949479065 acc:0.7576161589227385\r\n",
      "curr: 15500 train loss: 0.49376306218187316 acc:0.7569834204244887\r\n",
      "curr: 16000 train loss: 0.4935326040295495 acc:0.7578276357727642\r\n",
      "curr: 16500 train loss: 0.49202952379614934 acc:0.7586206896551724\r\n",
      "correct: 12805\r\n",
      "epochs 28 train loss: 0.49235487074503537 acc: 0.7581409117821196\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.36279429226042587 acc:0.8303393213572854\r\n",
      "curr: 1000 train loss: 0.44452743986976334 acc:0.7542457542457542\r\n",
      "curr: 1500 train loss: 0.4388750488725669 acc:0.759493670886076\r\n",
      "curr: 2000 train loss: 0.425476987024992 acc:0.769615192403798\r\n",
      "curr: 2500 train loss: 0.44448693945924606 acc:0.7604958016793283\r\n",
      "curr: 3000 train loss: 0.46303862790097833 acc:0.7537487504165278\r\n",
      "curr: 3500 train loss: 0.47086460530909113 acc:0.7512139388746073\r\n",
      "curr: 4000 train loss: 0.4768222751330286 acc:0.7525618595351162\r\n",
      "curr: 4500 train loss: 0.48310429657513376 acc:0.7527216174183515\r\n",
      "curr: 5000 train loss: 0.48354569822567944 acc:0.7534493101379725\r\n",
      "curr: 5500 train loss: 0.48625124737625336 acc:0.7520450827122341\r\n",
      "curr: 6000 train loss: 0.4905038531711207 acc:0.7482086318946842\r\n",
      "curr: 6500 train loss: 0.48778820768051107 acc:0.7501922781110598\r\n",
      "curr: 7000 train loss: 0.4883314177817942 acc:0.7498928724467934\r\n",
      "curr: 7500 train loss: 0.49202691532692694 acc:0.7475003332888949\r\n",
      "curr: 8000 train loss: 0.49279791129980705 acc:0.7471566054243219\r\n",
      "curr: 8500 train loss: 0.49448390813145 acc:0.7473238442536172\r\n",
      "curr: 9000 train loss: 0.49440169063913386 acc:0.7480279968892345\r\n",
      "curr: 9500 train loss: 0.4947765648697495 acc:0.7472897589727397\r\n",
      "curr: 10000 train loss: 0.4960485518653101 acc:0.7471252874712528\r\n",
      "curr: 10500 train loss: 0.49541486136158414 acc:0.7498333492048377\r\n",
      "curr: 11000 train loss: 0.49271110989901357 acc:0.7515680392691574\r\n",
      "curr: 11500 train loss: 0.4918836136649497 acc:0.7528041039909573\r\n",
      "curr: 12000 train loss: 0.49248143076816364 acc:0.752020664944588\r\n",
      "curr: 12500 train loss: 0.4923621615990006 acc:0.7522598192144628\r\n",
      "curr: 13000 train loss: 0.49243609937512045 acc:0.7514037381739866\r\n",
      "curr: 13500 train loss: 0.49069431785848433 acc:0.7526849862973113\r\n",
      "curr: 14000 train loss: 0.4886932791515929 acc:0.7539461467038069\r\n",
      "curr: 14500 train loss: 0.4869340343117085 acc:0.7555341010964761\r\n",
      "curr: 15000 train loss: 0.4864051560030944 acc:0.756882874475035\r\n",
      "curr: 15500 train loss: 0.48822635309528606 acc:0.7557576930520612\r\n",
      "curr: 16000 train loss: 0.48800971241778973 acc:0.7564527217048934\r\n",
      "curr: 16500 train loss: 0.48691084997649003 acc:0.7568632204108842\r\n",
      "correct: 12776\r\n",
      "epochs 29 train loss: 0.4877807466302385 acc: 0.7564239194789817\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.36518876243067805 acc:0.8363273453093812\r\n",
      "curr: 1000 train loss: 0.446788688135659 acc:0.7582417582417582\r\n",
      "curr: 1500 train loss: 0.43646218483567467 acc:0.7634910059960026\r\n",
      "curr: 2000 train loss: 0.42457344908530176 acc:0.7731134432783608\r\n",
      "curr: 2500 train loss: 0.4541185988643608 acc:0.7608956417433027\r\n",
      "curr: 3000 train loss: 0.46966316088561766 acc:0.7564145284905032\r\n",
      "curr: 3500 train loss: 0.475263387613375 acc:0.7543558983147672\r\n",
      "curr: 4000 train loss: 0.4813371549140784 acc:0.754561359660085\r\n",
      "curr: 4500 train loss: 0.48276196556248985 acc:0.7558320373250389\r\n",
      "curr: 5000 train loss: 0.48395567996232935 acc:0.7546490701859628\r\n",
      "curr: 5500 train loss: 0.48642672654943403 acc:0.7534993637520451\r\n",
      "curr: 6000 train loss: 0.4906884509800452 acc:0.7508748541909682\r\n",
      "curr: 6500 train loss: 0.48809015622258883 acc:0.7518843254883864\r\n",
      "curr: 7000 train loss: 0.4886051756029924 acc:0.7508927296100557\r\n",
      "curr: 7500 train loss: 0.49262874334292506 acc:0.7488334888681509\r\n",
      "curr: 8000 train loss: 0.49255437288035175 acc:0.7497812773403325\r\n",
      "curr: 8500 train loss: 0.4941111240986455 acc:0.7500294083049053\r\n",
      "curr: 9000 train loss: 0.4942924113174513 acc:0.7498055771580936\r\n",
      "curr: 9500 train loss: 0.4945871686783464 acc:0.7496053047047679\r\n",
      "curr: 10000 train loss: 0.49625905786233465 acc:0.7489251074892511\r\n",
      "curr: 10500 train loss: 0.4952827035958963 acc:0.7514522426435578\r\n",
      "curr: 11000 train loss: 0.49271989529974064 acc:0.7530224525043178\r\n",
      "curr: 11500 train loss: 0.4922857192977158 acc:0.7537605425615164\r\n",
      "curr: 12000 train loss: 0.4926528892552503 acc:0.7531872343971335\r\n",
      "curr: 12500 train loss: 0.49232344189327687 acc:0.7537796976241901\r\n",
      "curr: 13000 train loss: 0.49236332551355033 acc:0.7527113298977002\r\n",
      "curr: 13500 train loss: 0.4909042801101412 acc:0.7543144952225761\r\n",
      "curr: 14000 train loss: 0.4891540160067723 acc:0.7556603099778587\r\n",
      "curr: 14500 train loss: 0.48758943855556586 acc:0.756982277084339\r\n",
      "curr: 15000 train loss: 0.4870687255624013 acc:0.7577494833677755\r\n",
      "curr: 15500 train loss: 0.48835473586348466 acc:0.7567898845235791\r\n",
      "curr: 16000 train loss: 0.48820591233239846 acc:0.7575776513967877\r\n",
      "curr: 16500 train loss: 0.4867870201128823 acc:0.7584388824919702\r\n",
      "correct: 12797\r\n",
      "epochs 30 train loss: 0.4877029349375324 acc: 0.7576672587329781\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.36721463903229123 acc:0.8263473053892215\r\n",
      "curr: 1000 train loss: 0.44610842175256427 acc:0.7492507492507493\r\n",
      "curr: 1500 train loss: 0.43439695373142495 acc:0.7581612258494337\r\n",
      "curr: 2000 train loss: 0.4234961198022056 acc:0.7721139430284858\r\n",
      "curr: 2500 train loss: 0.4459007881187151 acc:0.7624950019992003\r\n",
      "curr: 3000 train loss: 0.4623245506522289 acc:0.757080973008997\r\n",
      "curr: 3500 train loss: 0.49559181179475276 acc:0.7534990002856327\r\n",
      "curr: 4000 train loss: 0.49759591212360327 acc:0.7563109222694326\r\n",
      "curr: 4500 train loss: 0.49744399464450395 acc:0.7578315929793379\r\n",
      "curr: 5000 train loss: 0.496680782419328 acc:0.7564487102579485\r\n",
      "curr: 5500 train loss: 0.4977544765141145 acc:0.7553172150518087\r\n",
      "curr: 6000 train loss: 0.502886578910761 acc:0.7520413264455924\r\n",
      "curr: 6500 train loss: 0.4991388770310875 acc:0.753576372865713\r\n",
      "curr: 7000 train loss: 0.49889169225358226 acc:0.7534637908870161\r\n",
      "curr: 7500 train loss: 0.5020892575322432 acc:0.7509665377949607\r\n",
      "curr: 8000 train loss: 0.5018138091028911 acc:0.750281214848144\r\n",
      "curr: 8500 train loss: 0.5034430006621919 acc:0.7499117750852841\r\n",
      "curr: 9000 train loss: 0.5029264825149795 acc:0.750361070992112\r\n",
      "curr: 9500 train loss: 0.5031753093585152 acc:0.7496053047047679\r\n",
      "curr: 10000 train loss: 0.5038138663900678 acc:0.7495250474952505\r\n",
      "curr: 10500 train loss: 0.5023367836449258 acc:0.751737929720979\r\n",
      "curr: 11000 train loss: 0.4991622107775668 acc:0.7537496591218981\r\n",
      "curr: 11500 train loss: 0.4983084311045029 acc:0.7547169811320755\r\n",
      "curr: 12000 train loss: 0.4978610518060005 acc:0.7548537621864845\r\n",
      "curr: 12500 train loss: 0.49796256661127325 acc:0.7552195824334054\r\n",
      "curr: 13000 train loss: 0.49773952292750406 acc:0.7544804245827244\r\n",
      "curr: 13500 train loss: 0.49591581793874706 acc:0.7563143470854011\r\n",
      "curr: 14000 train loss: 0.4941232266105379 acc:0.7576601671309192\r\n",
      "curr: 14500 train loss: 0.4921110511798974 acc:0.7592579822081236\r\n",
      "curr: 15000 train loss: 0.49141970922434247 acc:0.7602159856009599\r\n",
      "curr: 15500 train loss: 0.4924624384601368 acc:0.759370363202374\r\n",
      "curr: 16000 train loss: 0.4921609259229447 acc:0.7598275107805762\r\n",
      "curr: 16500 train loss: 0.49071478345877556 acc:0.7601963517362584\r\n",
      "correct: 12823\r\n",
      "epochs 31 train loss: 0.4915863119438073 acc: 0.7592066311426879\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.36545334673621754 acc:0.8303393213572854\r\n",
      "curr: 1000 train loss: 0.4484662441323114 acc:0.7482517482517482\r\n",
      "curr: 1500 train loss: 0.434347690061798 acc:0.7588274483677548\r\n",
      "curr: 2000 train loss: 0.42394995320389744 acc:0.768615692153923\r\n",
      "curr: 2500 train loss: 0.4580012453948328 acc:0.7568972411035586\r\n",
      "curr: 3000 train loss: 0.4726767502155505 acc:0.7527490836387871\r\n",
      "curr: 3500 train loss: 0.47896244731332765 acc:0.7500714081690946\r\n",
      "curr: 4000 train loss: 0.4847564979714237 acc:0.7495626093476631\r\n",
      "curr: 4500 train loss: 0.48753026227622875 acc:0.7509442346145301\r\n",
      "curr: 5000 train loss: 0.4870457923460963 acc:0.7516496700659868\r\n",
      "curr: 5500 train loss: 0.488959519884931 acc:0.7502272314124705\r\n",
      "curr: 6000 train loss: 0.49410001206098936 acc:0.747708715214131\r\n",
      "curr: 6500 train loss: 0.4909850936023143 acc:0.7492693431779727\r\n",
      "curr: 7000 train loss: 0.4915544766213434 acc:0.748750178545922\r\n",
      "curr: 7500 train loss: 0.4944305410041561 acc:0.7468337554992668\r\n",
      "curr: 8000 train loss: 0.4943171901371929 acc:0.7479065116860393\r\n",
      "curr: 8500 train loss: 0.49633798699431525 acc:0.7481472767909658\r\n",
      "curr: 9000 train loss: 0.49629045674746075 acc:0.748916787023664\r\n",
      "curr: 9500 train loss: 0.4971023267532299 acc:0.7482370276812967\r\n",
      "curr: 10000 train loss: 0.4974352888268441 acc:0.7487251274872513\r\n",
      "curr: 10500 train loss: 0.496972156908184 acc:0.7513570136177506\r\n",
      "curr: 11000 train loss: 0.4938182486101622 acc:0.7534769566403055\r\n",
      "curr: 11500 train loss: 0.4929342022784295 acc:0.7549778280149553\r\n",
      "curr: 12000 train loss: 0.4928806516203468 acc:0.7548537621864845\r\n",
      "curr: 12500 train loss: 0.49322012561284145 acc:0.7549796016318695\r\n",
      "curr: 13000 train loss: 0.49328075066904264 acc:0.7537881701407584\r\n",
      "curr: 13500 train loss: 0.4917644595926922 acc:0.7550551810976964\r\n",
      "curr: 14000 train loss: 0.48982197773765745 acc:0.7564459681451325\r\n",
      "curr: 14500 train loss: 0.48785373751044103 acc:0.7582235707882216\r\n",
      "curr: 15000 train loss: 0.48720804518868027 acc:0.758749416705553\r\n",
      "curr: 15500 train loss: 0.48851611571429515 acc:0.7577575640281272\r\n",
      "curr: 16000 train loss: 0.4883331833397268 acc:0.758265108430723\r\n",
      "curr: 16500 train loss: 0.4871183068697247 acc:0.7587418944306406\r\n",
      "correct: 12805\r\n",
      "epochs 32 train loss: 0.487902982363181 acc: 0.7581409117821196\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3756494997967274 acc:0.8303393213572854\r\n",
      "curr: 1000 train loss: 0.4519987891756871 acc:0.7562437562437563\r\n",
      "curr: 1500 train loss: 0.4392317816427023 acc:0.7621585609593604\r\n",
      "curr: 2000 train loss: 0.4269147096104944 acc:0.767616191904048\r\n",
      "curr: 2500 train loss: 0.45437973054345476 acc:0.7604958016793283\r\n",
      "curr: 3000 train loss: 0.46988392604348983 acc:0.7537487504165278\r\n",
      "curr: 3500 train loss: 0.47637396169219287 acc:0.7520708369037418\r\n",
      "curr: 4000 train loss: 0.4822889399844052 acc:0.7528117970507373\r\n",
      "curr: 4500 train loss: 0.48532790772349427 acc:0.7542768273716952\r\n",
      "curr: 5000 train loss: 0.4857888085957653 acc:0.7534493101379725\r\n",
      "curr: 5500 train loss: 0.4876955870767443 acc:0.7527722232321397\r\n",
      "curr: 6000 train loss: 0.49132280474776624 acc:0.7500416597233794\r\n",
      "curr: 6500 train loss: 0.4886362517295118 acc:0.7518843254883864\r\n",
      "curr: 7000 train loss: 0.489154891817427 acc:0.7513212398228825\r\n",
      "curr: 7500 train loss: 0.49256810528479084 acc:0.7497666977736301\r\n",
      "curr: 8000 train loss: 0.49248062869737047 acc:0.7509061367329084\r\n",
      "curr: 8500 train loss: 0.49409503411526406 acc:0.7512057405011175\r\n",
      "curr: 9000 train loss: 0.4939320061113392 acc:0.7515831574269526\r\n",
      "curr: 9500 train loss: 0.49446499603285765 acc:0.7512893379644248\r\n",
      "curr: 10000 train loss: 0.4956516412299048 acc:0.7515248475152485\r\n",
      "curr: 10500 train loss: 0.4944655043547652 acc:0.7537377392629273\r\n",
      "curr: 11000 train loss: 0.4913007119383148 acc:0.7558403781474411\r\n",
      "curr: 11500 train loss: 0.49040792940878136 acc:0.7567168072341536\r\n",
      "curr: 12000 train loss: 0.49049479335059437 acc:0.7565202899758353\r\n",
      "curr: 12500 train loss: 0.4905142109668035 acc:0.7574594032477402\r\n",
      "curr: 13000 train loss: 0.4901315668179724 acc:0.7572494423505884\r\n",
      "curr: 13500 train loss: 0.48864564597344606 acc:0.7586104732982742\r\n",
      "curr: 14000 train loss: 0.4868022461416888 acc:0.7595171773444754\r\n",
      "curr: 14500 train loss: 0.4849595393514303 acc:0.7609820012412937\r\n",
      "curr: 15000 train loss: 0.48462853978368825 acc:0.7619492033864409\r\n",
      "curr: 15500 train loss: 0.4857617205638196 acc:0.7611766982775304\r\n",
      "curr: 16000 train loss: 0.4856006971496525 acc:0.7620773701643647\r\n",
      "curr: 16500 train loss: 0.48441505650031336 acc:0.762256832919217\r\n",
      "correct: 12862\r\n",
      "epochs 33 train loss: 0.48547612456856104 acc: 0.7615156897572528\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.35974241321263123 acc:0.8243512974051896\r\n",
      "curr: 1000 train loss: 0.43697018988233877 acc:0.7642357642357642\r\n",
      "curr: 1500 train loss: 0.42706376368920895 acc:0.7721518987341772\r\n",
      "curr: 2000 train loss: 0.41731587757603594 acc:0.7796101949025487\r\n",
      "curr: 2500 train loss: 0.4780472371150791 acc:0.7680927628948421\r\n",
      "curr: 3000 train loss: 0.48788656516212797 acc:0.7634121959346885\r\n",
      "curr: 3500 train loss: 0.5095185500684831 acc:0.7609254498714653\r\n",
      "curr: 4000 train loss: 0.5106025725458371 acc:0.7610597350662335\r\n",
      "curr: 4500 train loss: 0.5085167921859008 acc:0.7629415685403244\r\n",
      "curr: 5000 train loss: 0.50625451840945 acc:0.7614477104579084\r\n",
      "curr: 5500 train loss: 0.5066152647341721 acc:0.7602254135611707\r\n",
      "curr: 6000 train loss: 0.5093794053139191 acc:0.7567072154640894\r\n",
      "curr: 6500 train loss: 0.5047339539762453 acc:0.7572681125980618\r\n",
      "curr: 7000 train loss: 0.5035425178274998 acc:0.7568918725896301\r\n",
      "curr: 7500 train loss: 0.5054008288540527 acc:0.754966004532729\r\n",
      "curr: 8000 train loss: 0.5045614609161743 acc:0.7550306211723534\r\n",
      "curr: 8500 train loss: 0.5056706824991516 acc:0.7547347370897541\r\n",
      "curr: 9000 train loss: 0.5052559956146753 acc:0.7545828241306521\r\n",
      "curr: 9500 train loss: 0.5051456391752603 acc:0.7534996316177245\r\n",
      "curr: 10000 train loss: 0.5057861732439978 acc:0.7533246675332467\r\n",
      "curr: 10500 train loss: 0.5042045576716796 acc:0.7558327778306828\r\n",
      "curr: 11000 train loss: 0.501129517078293 acc:0.7569311880738114\r\n",
      "curr: 11500 train loss: 0.500909230897276 acc:0.7575862968437527\r\n",
      "curr: 12000 train loss: 0.5003946884970804 acc:0.7570202483126406\r\n",
      "curr: 12500 train loss: 0.5005033459214062 acc:0.7572194224462043\r\n",
      "curr: 13000 train loss: 0.49935103188273994 acc:0.7567110222290593\r\n",
      "curr: 13500 train loss: 0.49733510378046236 acc:0.75809199318569\r\n",
      "curr: 14000 train loss: 0.4951720789407865 acc:0.7591600599957146\r\n",
      "curr: 14500 train loss: 0.49282619262052235 acc:0.7607751189573133\r\n",
      "curr: 15000 train loss: 0.49188707052321257 acc:0.7614159056062929\r\n",
      "curr: 15500 train loss: 0.49246003056199134 acc:0.7609831623766209\r\n",
      "curr: 16000 train loss: 0.4919429832630855 acc:0.7615149053184176\r\n",
      "curr: 16500 train loss: 0.4906772649096266 acc:0.7615296042664081\r\n",
      "correct: 12846\r\n",
      "epochs 34 train loss: 0.49316680087013903 acc: 0.7605683836589698\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3704878404932324 acc:0.8203592814371258\r\n",
      "curr: 1000 train loss: 0.4440528795502943 acc:0.7472527472527473\r\n",
      "curr: 1500 train loss: 0.43129539162246483 acc:0.759493670886076\r\n",
      "curr: 2000 train loss: 0.42352590027361914 acc:0.7706146926536732\r\n",
      "curr: 2500 train loss: 0.4507157426339591 acc:0.7624950019992003\r\n",
      "curr: 3000 train loss: 0.4642957848171375 acc:0.7580806397867378\r\n",
      "curr: 3500 train loss: 0.46956390696068756 acc:0.7540702656383891\r\n",
      "curr: 4000 train loss: 0.4767351792250513 acc:0.7538115471132217\r\n",
      "curr: 4500 train loss: 0.4801228141139577 acc:0.7556098644745612\r\n",
      "curr: 5000 train loss: 0.48109293277656895 acc:0.755248950209958\r\n",
      "curr: 5500 train loss: 0.4840940327881823 acc:0.754408289401927\r\n",
      "curr: 6000 train loss: 0.4877103179165138 acc:0.7518746875520746\r\n",
      "curr: 6500 train loss: 0.48473436039295387 acc:0.7534225503768651\r\n",
      "curr: 7000 train loss: 0.4851839750184978 acc:0.7533209541494073\r\n",
      "curr: 7500 train loss: 0.48843556231667773 acc:0.7516331155845887\r\n",
      "curr: 8000 train loss: 0.48900010558843265 acc:0.752405949256343\r\n",
      "curr: 8500 train loss: 0.490901697104291 acc:0.7521468062580873\r\n",
      "curr: 9000 train loss: 0.4910314040092991 acc:0.7528052438617931\r\n",
      "curr: 9500 train loss: 0.4917417863501525 acc:0.752657614987896\r\n",
      "curr: 10000 train loss: 0.4925213162992069 acc:0.7532246775322468\r\n",
      "curr: 10500 train loss: 0.4913260266847268 acc:0.7556423197790687\r\n",
      "curr: 11000 train loss: 0.4883801990671027 acc:0.7567493864194165\r\n",
      "curr: 11500 train loss: 0.4877577023393858 acc:0.7581079906095122\r\n",
      "curr: 12000 train loss: 0.48754293627485085 acc:0.7577701858178485\r\n",
      "curr: 12500 train loss: 0.4876232425130311 acc:0.7580193584513238\r\n",
      "curr: 13000 train loss: 0.48738927094506607 acc:0.7573263595108068\r\n",
      "curr: 13500 train loss: 0.4859121839797955 acc:0.7584623361232501\r\n",
      "curr: 14000 train loss: 0.48382041408661475 acc:0.7596600242839797\r\n",
      "curr: 14500 train loss: 0.4817786927595841 acc:0.7613957658092545\r\n",
      "curr: 15000 train loss: 0.4812372525951393 acc:0.7620158656089594\r\n",
      "curr: 15500 train loss: 0.48243729207458047 acc:0.7612412102445003\r\n",
      "curr: 16000 train loss: 0.4823194782334938 acc:0.7616398975064058\r\n",
      "curr: 16500 train loss: 0.4812033524703416 acc:0.7617114114296103\r\n",
      "correct: 12848\r\n",
      "epochs 35 train loss: 0.4835158024387789 acc: 0.7606867969212552\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.36245633775137176 acc:0.8183632734530938\r\n",
      "curr: 1000 train loss: 0.4396464146317057 acc:0.7582417582417582\r\n",
      "curr: 1500 train loss: 0.42711137285247547 acc:0.765489673550966\r\n",
      "curr: 2000 train loss: 0.4234272412772649 acc:0.7731134432783608\r\n",
      "curr: 2500 train loss: 0.44708629752483287 acc:0.7652938824470212\r\n",
      "curr: 3000 train loss: 0.4630374954788808 acc:0.7597467510829723\r\n",
      "curr: 3500 train loss: 0.4689998302304109 acc:0.7569265924021709\r\n",
      "curr: 4000 train loss: 0.47499179711485706 acc:0.7565608597850537\r\n",
      "curr: 4500 train loss: 0.48031710211996737 acc:0.758498111530771\r\n",
      "curr: 5000 train loss: 0.48120404540495554 acc:0.7570485902819436\r\n",
      "curr: 5500 train loss: 0.4833465993158205 acc:0.7558625704417379\r\n",
      "curr: 6000 train loss: 0.48770332045731446 acc:0.7525412431261457\r\n",
      "curr: 6500 train loss: 0.48525105693009796 acc:0.7540378403322566\r\n",
      "curr: 7000 train loss: 0.485410631047355 acc:0.7534637908870161\r\n",
      "curr: 7500 train loss: 0.48898751935967044 acc:0.7520330622583655\r\n",
      "curr: 8000 train loss: 0.48921360516582574 acc:0.7526559180102487\r\n",
      "curr: 8500 train loss: 0.4916079204124297 acc:0.7521468062580873\r\n",
      "curr: 9000 train loss: 0.49150007571931015 acc:0.7528052438617931\r\n",
      "curr: 9500 train loss: 0.4923696525442633 acc:0.7519208504367961\r\n",
      "curr: 10000 train loss: 0.4930990014130503 acc:0.7524247575242475\r\n",
      "curr: 10500 train loss: 0.49188396184858096 acc:0.7550709456242263\r\n",
      "curr: 11000 train loss: 0.48932430055985915 acc:0.7562039814562312\r\n",
      "curr: 11500 train loss: 0.48929271856783474 acc:0.7570646030779932\r\n",
      "curr: 12000 train loss: 0.4891385957433479 acc:0.7568535955337056\r\n",
      "curr: 12500 train loss: 0.48898090201209343 acc:0.7573794096472283\r\n",
      "curr: 13000 train loss: 0.488586941943537 acc:0.7574032766710254\r\n",
      "curr: 13500 train loss: 0.48653358094995874 acc:0.7591289534108585\r\n",
      "curr: 14000 train loss: 0.48463765505551465 acc:0.7605171059210056\r\n",
      "curr: 14500 train loss: 0.48276856169024707 acc:0.761602648093235\r\n",
      "curr: 15000 train loss: 0.4820029110685698 acc:0.7620825278314779\r\n",
      "curr: 15500 train loss: 0.48342537296269317 acc:0.760918650409651\r\n",
      "curr: 16000 train loss: 0.48311455731491443 acc:0.7615774014124117\r\n",
      "curr: 16500 train loss: 0.4817485615026683 acc:0.7620750257560148\r\n",
      "correct: 12854\r\n",
      "epochs 36 train loss: 0.4825425637346274 acc: 0.7610420367081113\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.35896997980154316 acc:0.8243512974051896\r\n",
      "curr: 1000 train loss: 0.4433182675992496 acc:0.7532467532467533\r\n",
      "curr: 1500 train loss: 0.4296548737653969 acc:0.760159893404397\r\n",
      "curr: 2000 train loss: 0.4204451029830406 acc:0.7701149425287356\r\n",
      "curr: 2500 train loss: 0.4586882762660557 acc:0.7632946821271491\r\n",
      "curr: 3000 train loss: 0.4735552441408465 acc:0.7587470843052316\r\n",
      "curr: 3500 train loss: 0.47781869140828426 acc:0.7566409597257926\r\n",
      "curr: 4000 train loss: 0.48324687456011617 acc:0.7570607348162959\r\n",
      "curr: 4500 train loss: 0.4842236466254784 acc:0.7593868029326817\r\n",
      "curr: 5000 train loss: 0.4855925030318636 acc:0.7580483903219356\r\n",
      "curr: 5500 train loss: 0.4880057969164421 acc:0.7565897109616433\r\n",
      "curr: 6000 train loss: 0.49164464303404026 acc:0.7542076320613231\r\n",
      "curr: 6500 train loss: 0.48895565258405993 acc:0.7551145977541917\r\n",
      "curr: 7000 train loss: 0.48872444653046365 acc:0.7548921582631053\r\n",
      "curr: 7500 train loss: 0.4918752158057142 acc:0.7524330089321424\r\n",
      "curr: 8000 train loss: 0.4915492349629333 acc:0.7527809023872016\r\n",
      "curr: 8500 train loss: 0.49310196320864164 acc:0.7529702387954358\r\n",
      "curr: 9000 train loss: 0.4931307249986857 acc:0.7533607376958116\r\n",
      "curr: 9500 train loss: 0.49365527890463734 acc:0.7525523629091675\r\n",
      "curr: 10000 train loss: 0.49462922343022137 acc:0.7525247475252475\r\n",
      "curr: 10500 train loss: 0.4937131184669985 acc:0.7547852585468051\r\n",
      "curr: 11000 train loss: 0.49040510504641643 acc:0.7564766839378239\r\n",
      "curr: 11500 train loss: 0.4894944340226975 acc:0.7577601947656726\r\n",
      "curr: 12000 train loss: 0.48966034785615903 acc:0.7566869427547704\r\n",
      "curr: 12500 train loss: 0.48940439973237804 acc:0.7573794096472283\r\n",
      "curr: 13000 train loss: 0.48869609960195737 acc:0.7570186908699331\r\n",
      "curr: 13500 train loss: 0.48698088154951863 acc:0.7587586104732983\r\n",
      "curr: 14000 train loss: 0.4851811646820324 acc:0.7599457181629884\r\n",
      "curr: 14500 train loss: 0.48303151166802194 acc:0.7616716088545618\r\n",
      "curr: 15000 train loss: 0.4823384463963374 acc:0.7624825011665889\r\n",
      "curr: 15500 train loss: 0.48372294709357405 acc:0.76143474614541\r\n",
      "curr: 16000 train loss: 0.48364137563397414 acc:0.7619523779763765\r\n",
      "curr: 16500 train loss: 0.4824712132071202 acc:0.7626810496333556\r\n",
      "correct: 12871\r\n",
      "epochs 37 train loss: 0.48283921896002346 acc: 0.762048549437537\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3571068207290502 acc:0.8283433133732535\r\n",
      "curr: 1000 train loss: 0.4363391270584413 acc:0.7622377622377622\r\n",
      "curr: 1500 train loss: 0.4251205362201613 acc:0.7701532311792139\r\n",
      "curr: 2000 train loss: 0.4125942149234525 acc:0.777111444277861\r\n",
      "curr: 2500 train loss: 0.43748915395757204 acc:0.7680927628948421\r\n",
      "curr: 3000 train loss: 0.4556070954698239 acc:0.7620793068977008\r\n",
      "curr: 3500 train loss: 0.4625681153110075 acc:0.7580691231076835\r\n",
      "curr: 4000 train loss: 0.4699285083446481 acc:0.7570607348162959\r\n",
      "curr: 4500 train loss: 0.4743323734650131 acc:0.7596089757831593\r\n",
      "curr: 5000 train loss: 0.47469853292116865 acc:0.7596480703859229\r\n",
      "curr: 5500 train loss: 0.47747784037255986 acc:0.7582257771314307\r\n",
      "curr: 6000 train loss: 0.48129802454036835 acc:0.7552074654224296\r\n",
      "curr: 6500 train loss: 0.47846643663307703 acc:0.7571142901092139\r\n",
      "curr: 7000 train loss: 0.4793681927812228 acc:0.7574632195400657\r\n",
      "curr: 7500 train loss: 0.48263125503921217 acc:0.7546993734168778\r\n",
      "curr: 8000 train loss: 0.4832377750088658 acc:0.7554055743032121\r\n",
      "curr: 8500 train loss: 0.4854218843621892 acc:0.7548523703093754\r\n",
      "curr: 9000 train loss: 0.4854090952057681 acc:0.7552494167314743\r\n",
      "curr: 9500 train loss: 0.4862689050281637 acc:0.7547626565624671\r\n",
      "curr: 10000 train loss: 0.4874414006268335 acc:0.7551244875512448\r\n",
      "curr: 10500 train loss: 0.48684628074096586 acc:0.7574516712694029\r\n",
      "curr: 11000 train loss: 0.48421279009317125 acc:0.7594764112353423\r\n",
      "curr: 11500 train loss: 0.48338334418418977 acc:0.7611512042431093\r\n",
      "curr: 12000 train loss: 0.483599562506789 acc:0.7609365886176152\r\n",
      "curr: 12500 train loss: 0.48362389619035845 acc:0.7610591152707783\r\n",
      "curr: 13000 train loss: 0.4835179753749422 acc:0.7606337974002\r\n",
      "curr: 13500 train loss: 0.4819494458893083 acc:0.7620176283238279\r\n",
      "curr: 14000 train loss: 0.4801039994946419 acc:0.7635168916505964\r\n",
      "curr: 14500 train loss: 0.47828903199584183 acc:0.7650506861595752\r\n",
      "curr: 15000 train loss: 0.47792441046596434 acc:0.7658822745150323\r\n",
      "curr: 15500 train loss: 0.4791284325641069 acc:0.7652409521966325\r\n",
      "curr: 16000 train loss: 0.4788935921184717 acc:0.7655146553340416\r\n",
      "curr: 16500 train loss: 0.47791150477747457 acc:0.7658929761832616\r\n",
      "correct: 12919\r\n",
      "epochs 38 train loss: 0.47868641890221797 acc: 0.764890467732386\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.35595710515674756 acc:0.8323353293413174\r\n",
      "curr: 1000 train loss: 0.4318671693944583 acc:0.7582417582417582\r\n",
      "curr: 1500 train loss: 0.4244709816536201 acc:0.765489673550966\r\n",
      "curr: 2000 train loss: 0.41301024357690613 acc:0.7746126936531734\r\n",
      "curr: 2500 train loss: 0.440352855723178 acc:0.76609356257497\r\n",
      "curr: 3000 train loss: 0.4588038822688352 acc:0.7600799733422192\r\n",
      "curr: 3500 train loss: 0.5231111468341418 acc:0.757212225078549\r\n",
      "curr: 4000 train loss: 0.5222534295399089 acc:0.7565608597850537\r\n",
      "curr: 4500 train loss: 0.5202929240647713 acc:0.7589424572317263\r\n",
      "curr: 5000 train loss: 0.5170767964385024 acc:0.7580483903219356\r\n",
      "curr: 5500 train loss: 0.5160538255773452 acc:0.7571350663515725\r\n",
      "curr: 6000 train loss: 0.5185751778107798 acc:0.7537077153807699\r\n",
      "curr: 6500 train loss: 0.5134216860168607 acc:0.7549607752653438\r\n",
      "curr: 7000 train loss: 0.5117422385851922 acc:0.7541779745750607\r\n",
      "curr: 7500 train loss: 0.5124787826671319 acc:0.7526996400479936\r\n",
      "curr: 8000 train loss: 0.5103916379331124 acc:0.753405824271966\r\n",
      "curr: 8500 train loss: 0.5105944975318062 acc:0.753558404893542\r\n",
      "curr: 9000 train loss: 0.5093453081738123 acc:0.7544717253638484\r\n",
      "curr: 9500 train loss: 0.5092120521575212 acc:0.75455215240501\r\n",
      "curr: 10000 train loss: 0.508994226223556 acc:0.7544245575442455\r\n",
      "curr: 10500 train loss: 0.5072737407369996 acc:0.7567850680887535\r\n",
      "curr: 11000 train loss: 0.5037865142029526 acc:0.7582037996545768\r\n",
      "curr: 11500 train loss: 0.5025063895761946 acc:0.7596730719067907\r\n",
      "curr: 12000 train loss: 0.5016025240911158 acc:0.7589367552703942\r\n",
      "curr: 12500 train loss: 0.5013096087387814 acc:0.7594592432605392\r\n",
      "curr: 13000 train loss: 0.500235258085329 acc:0.7587877855549573\r\n",
      "curr: 13500 train loss: 0.4977775972661592 acc:0.760239982223539\r\n",
      "curr: 14000 train loss: 0.4954454604209394 acc:0.761588457967288\r\n",
      "curr: 14500 train loss: 0.492799972981542 acc:0.7633266671264051\r\n",
      "curr: 15000 train loss: 0.49186349536307156 acc:0.7638824078394774\r\n",
      "curr: 15500 train loss: 0.49294478876878633 acc:0.762918521385717\r\n",
      "curr: 16000 train loss: 0.49270323740021477 acc:0.7635147803262297\r\n",
      "curr: 16500 train loss: 0.49123826021446304 acc:0.763771892612569\r\n",
      "correct: 12889\r\n",
      "epochs 39 train loss: 0.4926457024531251 acc: 0.7631142687981054\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.35787782889634673 acc:0.8323353293413174\r\n",
      "curr: 1000 train loss: 0.43844527821686563 acc:0.7602397602397603\r\n",
      "curr: 1500 train loss: 0.42530965630822026 acc:0.7668221185876083\r\n",
      "curr: 2000 train loss: 0.4125000676254083 acc:0.7756121939030485\r\n",
      "curr: 2500 train loss: 0.43248209161247986 acc:0.7700919632147141\r\n",
      "curr: 3000 train loss: 0.4524561920548974 acc:0.76541152949017\r\n",
      "curr: 3500 train loss: 0.4600133297105282 acc:0.7614967152242217\r\n",
      "curr: 4000 train loss: 0.4681082523726979 acc:0.7603099225193701\r\n",
      "curr: 4500 train loss: 0.47141265955139744 acc:0.761830704287936\r\n",
      "curr: 5000 train loss: 0.4734658330655097 acc:0.7614477104579084\r\n",
      "curr: 5500 train loss: 0.47648297949211704 acc:0.760407198691147\r\n",
      "curr: 6000 train loss: 0.48057614054598047 acc:0.7577070488251958\r\n",
      "curr: 6500 train loss: 0.4780201334724111 acc:0.7591139824642362\r\n",
      "curr: 7000 train loss: 0.4787343199120395 acc:0.7583202399657192\r\n",
      "curr: 7500 train loss: 0.4823885054726708 acc:0.7565657912278363\r\n",
      "curr: 8000 train loss: 0.4826522428379571 acc:0.7572803399575053\r\n",
      "curr: 8500 train loss: 0.48463952048279385 acc:0.7569697682625574\r\n",
      "curr: 9000 train loss: 0.48504299155982655 acc:0.757138095767137\r\n",
      "curr: 9500 train loss: 0.48617061540756323 acc:0.7565519419008525\r\n",
      "curr: 10000 train loss: 0.4869755774960162 acc:0.7567243275672433\r\n",
      "curr: 10500 train loss: 0.4866114094481008 acc:0.758975335682316\r\n",
      "curr: 11000 train loss: 0.48434078206841735 acc:0.7604763203345151\r\n",
      "curr: 11500 train loss: 0.48373720085767713 acc:0.7615859490479089\r\n",
      "curr: 12000 train loss: 0.48384706526669585 acc:0.7613532205649529\r\n",
      "curr: 12500 train loss: 0.484023358044055 acc:0.7615390768738501\r\n",
      "curr: 13000 train loss: 0.48330617313187063 acc:0.7614029690023845\r\n",
      "curr: 13500 train loss: 0.48162986852940753 acc:0.762387971261388\r\n",
      "curr: 14000 train loss: 0.4796315503408093 acc:0.7634454681808442\r\n",
      "curr: 14500 train loss: 0.4779517842146962 acc:0.7650506861595752\r\n",
      "curr: 15000 train loss: 0.47743277687835756 acc:0.7658822745150323\r\n",
      "curr: 15500 train loss: 0.4786609910974085 acc:0.7653054641636023\r\n",
      "curr: 16000 train loss: 0.4788480335332108 acc:0.765702143616024\r\n",
      "curr: 16500 train loss: 0.47769750318811005 acc:0.7660141809587298\r\n",
      "correct: 12925\r\n",
      "epochs 40 train loss: 0.47900435039101674 acc: 0.7652457075192421\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.351521207615015 acc:0.844311377245509\r\n",
      "curr: 1000 train loss: 0.4381303076052531 acc:0.7692307692307693\r\n",
      "curr: 1500 train loss: 0.42749485222395506 acc:0.7728181212524984\r\n",
      "curr: 2000 train loss: 0.4150704512062129 acc:0.7816091954022989\r\n",
      "curr: 2500 train loss: 0.44351084439001576 acc:0.7736905237904838\r\n",
      "curr: 3000 train loss: 0.4612206451614469 acc:0.7657447517494168\r\n",
      "curr: 3500 train loss: 0.4670319408039591 acc:0.7626392459297343\r\n",
      "curr: 4000 train loss: 0.47367033062942165 acc:0.7623094226443389\r\n",
      "curr: 4500 train loss: 0.4760182423281435 acc:0.7647189513441457\r\n",
      "curr: 5000 train loss: 0.4780870702149646 acc:0.7646470705858828\r\n",
      "curr: 5500 train loss: 0.4792894034112307 acc:0.7624068351208871\r\n",
      "curr: 6000 train loss: 0.4833677983291936 acc:0.7587068821863023\r\n",
      "curr: 6500 train loss: 0.48079635922628877 acc:0.7591139824642362\r\n",
      "curr: 7000 train loss: 0.48140679482559345 acc:0.7581774032281102\r\n",
      "curr: 7500 train loss: 0.4843569176069864 acc:0.7569657379016131\r\n",
      "curr: 8000 train loss: 0.48438276089787635 acc:0.7577802774653168\r\n",
      "curr: 8500 train loss: 0.486103318649093 acc:0.7576755675802846\r\n",
      "curr: 9000 train loss: 0.48642575971205415 acc:0.7575824908343517\r\n",
      "curr: 9500 train loss: 0.48755489499732274 acc:0.756446689822124\r\n",
      "curr: 10000 train loss: 0.4882343066752361 acc:0.7566243375662434\r\n",
      "curr: 10500 train loss: 0.48711120706082345 acc:0.7591657937339301\r\n",
      "curr: 11000 train loss: 0.4847027861428204 acc:0.7610217252977002\r\n",
      "curr: 11500 train loss: 0.4836109844177736 acc:0.7626293365794279\r\n",
      "curr: 12000 train loss: 0.4832079618350372 acc:0.762436463628031\r\n",
      "curr: 12500 train loss: 0.48293047674383666 acc:0.7632189424846012\r\n",
      "curr: 13000 train loss: 0.48258001753101337 acc:0.7631720636874086\r\n",
      "curr: 13500 train loss: 0.4803455613649514 acc:0.7651285089993334\r\n",
      "curr: 14000 train loss: 0.4792796780883246 acc:0.7660881365616742\r\n",
      "curr: 14500 train loss: 0.4772080876249118 acc:0.7670505482380525\r\n",
      "curr: 15000 train loss: 0.4764839361952349 acc:0.7674155056329578\r\n",
      "curr: 15500 train loss: 0.47731749886327796 acc:0.7667892394039094\r\n",
      "curr: 16000 train loss: 0.47750078267560575 acc:0.7670145615899007\r\n",
      "curr: 16500 train loss: 0.4761628644684221 acc:0.7672868311011454\r\n",
      "correct: 12943\r\n",
      "epochs 41 train loss: 0.4775856330225201 acc: 0.7663114268798106\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.34609637886986766 acc:0.8423153692614771\r\n",
      "curr: 1000 train loss: 0.4398240162298585 acc:0.7592407592407593\r\n",
      "curr: 1500 train loss: 0.425607612838148 acc:0.7668221185876083\r\n",
      "curr: 2000 train loss: 0.41270697257069944 acc:0.776111944027986\r\n",
      "curr: 2500 train loss: 0.4503650327707531 acc:0.7704918032786885\r\n",
      "curr: 3000 train loss: 0.46672161581223465 acc:0.7657447517494168\r\n",
      "curr: 3500 train loss: 0.47262353692419645 acc:0.760354184518709\r\n",
      "curr: 4000 train loss: 0.47913584637117523 acc:0.7605598600349912\r\n",
      "curr: 4500 train loss: 0.4830692488359984 acc:0.7622750499888914\r\n",
      "curr: 5000 train loss: 0.4835381371382463 acc:0.7604479104179164\r\n",
      "curr: 5500 train loss: 0.4857660176403663 acc:0.7587711325213597\r\n",
      "curr: 6000 train loss: 0.48860233380551044 acc:0.7565405765705716\r\n",
      "curr: 6500 train loss: 0.4854387445846387 acc:0.7577295800646054\r\n",
      "curr: 7000 train loss: 0.4853787738539222 acc:0.7571775460648479\r\n",
      "curr: 7500 train loss: 0.488796517726661 acc:0.7546993734168778\r\n",
      "curr: 8000 train loss: 0.4888941730075494 acc:0.7555305586801649\r\n",
      "curr: 8500 train loss: 0.49029656338998756 acc:0.755205269968239\r\n",
      "curr: 9000 train loss: 0.490295235982066 acc:0.7561382068659038\r\n",
      "curr: 9500 train loss: 0.4910422552130849 acc:0.7554994211135669\r\n",
      "curr: 10000 train loss: 0.49132866581659557 acc:0.7558244175582441\r\n",
      "curr: 10500 train loss: 0.49021133945741996 acc:0.7577373583468241\r\n",
      "curr: 11000 train loss: 0.4876551051546867 acc:0.7591128079265521\r\n",
      "curr: 11500 train loss: 0.48620658618948687 acc:0.7607164594383097\r\n",
      "curr: 12000 train loss: 0.4858513556322502 acc:0.760603283059745\r\n",
      "curr: 12500 train loss: 0.4860278976511344 acc:0.7610591152707783\r\n",
      "curr: 13000 train loss: 0.4855853287267838 acc:0.7610183832012922\r\n",
      "curr: 13500 train loss: 0.4836651803959376 acc:0.762313902673876\r\n",
      "curr: 14000 train loss: 0.48159835558927216 acc:0.7636597385901007\r\n",
      "curr: 14500 train loss: 0.47933646582024053 acc:0.7646369215916143\r\n",
      "curr: 15000 train loss: 0.4788543703937138 acc:0.7656156256249583\r\n",
      "curr: 15500 train loss: 0.47980766562586263 acc:0.7653699761305722\r\n",
      "curr: 16000 train loss: 0.47966461843552205 acc:0.7661396162739829\r\n",
      "curr: 16500 train loss: 0.4782229386791041 acc:0.7663171928974002\r\n",
      "correct: 12928\r\n",
      "epochs 42 train loss: 0.4801911969879477 acc: 0.7654233274126703\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3574851437743505 acc:0.8263473053892215\r\n",
      "curr: 1000 train loss: 0.4427136226755111 acc:0.7522477522477522\r\n",
      "curr: 1500 train loss: 0.4246782802480814 acc:0.7648234510326449\r\n",
      "curr: 2000 train loss: 0.41271978564235057 acc:0.775112443778111\r\n",
      "curr: 2500 train loss: 0.4359620792714992 acc:0.7684926029588165\r\n",
      "curr: 3000 train loss: 0.45326924366283483 acc:0.7634121959346885\r\n",
      "curr: 3500 train loss: 0.46064739988029496 acc:0.7592116538131962\r\n",
      "curr: 4000 train loss: 0.46768999689667806 acc:0.7588102974256435\r\n",
      "curr: 4500 train loss: 0.4729651066556213 acc:0.7600533214841146\r\n",
      "curr: 5000 train loss: 0.4768746984039377 acc:0.7580483903219356\r\n",
      "curr: 5500 train loss: 0.4797950277388219 acc:0.7573168514815488\r\n",
      "curr: 6000 train loss: 0.4831313024835502 acc:0.7538743542742876\r\n",
      "curr: 6500 train loss: 0.48049550588198603 acc:0.7544993077988001\r\n",
      "curr: 7000 train loss: 0.48079990387071087 acc:0.7547493215254963\r\n",
      "curr: 7500 train loss: 0.484070821520491 acc:0.7534995333955472\r\n",
      "curr: 8000 train loss: 0.4840522997703863 acc:0.7545306836645419\r\n",
      "curr: 8500 train loss: 0.4854279133877388 acc:0.7543818374308905\r\n",
      "curr: 9000 train loss: 0.4858293415116661 acc:0.7549161204310633\r\n",
      "curr: 9500 train loss: 0.48588811084007805 acc:0.7552889169561099\r\n",
      "curr: 10000 train loss: 0.4864721538563173 acc:0.7549245075492451\r\n",
      "curr: 10500 train loss: 0.4852358645301642 acc:0.757642129321017\r\n",
      "curr: 11000 train loss: 0.4826959613318247 acc:0.7592037087537497\r\n",
      "curr: 11500 train loss: 0.48170894675994996 acc:0.7604556125554299\r\n",
      "curr: 12000 train loss: 0.4814338601665748 acc:0.7596033663861345\r\n",
      "curr: 12500 train loss: 0.4812604658484028 acc:0.7603391728661707\r\n",
      "curr: 13000 train loss: 0.48070827175173425 acc:0.759941542958234\r\n",
      "curr: 13500 train loss: 0.4789590406114773 acc:0.7613510110362195\r\n",
      "curr: 14000 train loss: 0.47733985882855134 acc:0.7625169630740661\r\n",
      "curr: 14500 train loss: 0.4756865368729568 acc:0.7636025101717123\r\n",
      "curr: 15000 train loss: 0.4750569126143554 acc:0.7646156922871808\r\n",
      "curr: 15500 train loss: 0.4761325194712542 acc:0.7637571769563254\r\n",
      "curr: 16000 train loss: 0.47581721026857077 acc:0.764202237360165\r\n",
      "curr: 16500 train loss: 0.4746227135245698 acc:0.76468092842858\r\n",
      "correct: 12897\r\n",
      "epochs 43 train loss: 0.4763232028549136 acc: 0.7635879218472469\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.34713510125789787 acc:0.8343313373253493\r\n",
      "curr: 1000 train loss: 0.4379753178025695 acc:0.7602397602397603\r\n",
      "curr: 1500 train loss: 0.42574154565744166 acc:0.765489673550966\r\n",
      "curr: 2000 train loss: 0.4110192954911756 acc:0.7786106946526736\r\n",
      "curr: 2500 train loss: 0.4366155337355623 acc:0.7720911635345862\r\n",
      "curr: 3000 train loss: 0.45384782286714315 acc:0.7664111962679107\r\n",
      "curr: 3500 train loss: 0.4611537479998233 acc:0.7634961439588689\r\n",
      "curr: 4000 train loss: 0.4684370915719402 acc:0.7630592351912022\r\n",
      "curr: 4500 train loss: 0.47890390769626895 acc:0.763163741390802\r\n",
      "curr: 5000 train loss: 0.48026290023046214 acc:0.7620475904819036\r\n",
      "curr: 5500 train loss: 0.4818307011289487 acc:0.760407198691147\r\n",
      "curr: 6000 train loss: 0.48551543958904425 acc:0.757540409931678\r\n",
      "curr: 6500 train loss: 0.4823732449423223 acc:0.7591139824642362\r\n",
      "curr: 7000 train loss: 0.4828065551056139 acc:0.7594629338665905\r\n",
      "curr: 7500 train loss: 0.48585549393449695 acc:0.7577656312491667\r\n",
      "curr: 8000 train loss: 0.48578399042261905 acc:0.7580302462192225\r\n",
      "curr: 8500 train loss: 0.48743843398032 acc:0.7580284672391483\r\n",
      "curr: 9000 train loss: 0.48749849003321866 acc:0.758582379735585\r\n",
      "curr: 9500 train loss: 0.4891992947169876 acc:0.7567624460583097\r\n",
      "curr: 10000 train loss: 0.48995509515764735 acc:0.7564243575642435\r\n",
      "curr: 10500 train loss: 0.48916216740201357 acc:0.7591657937339301\r\n",
      "curr: 11000 train loss: 0.48647713190434877 acc:0.7607490228161077\r\n",
      "curr: 11500 train loss: 0.4848410148842638 acc:0.7621945917746283\r\n",
      "curr: 12000 train loss: 0.4845328003951771 acc:0.7616031997333556\r\n",
      "curr: 12500 train loss: 0.4848126422725627 acc:0.7620190384769219\r\n",
      "curr: 13000 train loss: 0.48393528850393797 acc:0.7619413891239135\r\n",
      "curr: 13500 train loss: 0.4819685479828988 acc:0.7634249314865565\r\n",
      "curr: 14000 train loss: 0.48016876808585607 acc:0.7644453967573744\r\n",
      "curr: 14500 train loss: 0.4781776293188317 acc:0.7658782152954968\r\n",
      "curr: 15000 train loss: 0.47739052198442383 acc:0.7665488967402173\r\n",
      "curr: 15500 train loss: 0.47859065985765936 acc:0.7658215598993613\r\n",
      "curr: 16000 train loss: 0.47815177732616165 acc:0.7662646084619711\r\n",
      "curr: 16500 train loss: 0.47680608359045357 acc:0.7665596024483364\r\n",
      "correct: 12932\r\n",
      "epochs 44 train loss: 0.47764186660053515 acc: 0.765660153937241\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.34809770648630417 acc:0.8383233532934131\r\n",
      "curr: 1000 train loss: 0.42860754968424053 acc:0.7652347652347652\r\n",
      "curr: 1500 train loss: 0.4137298395463463 acc:0.770819453697535\r\n",
      "curr: 2000 train loss: 0.403341711366736 acc:0.7796101949025487\r\n",
      "curr: 2500 train loss: 0.4299091663092329 acc:0.7732906837265094\r\n",
      "curr: 3000 train loss: 0.4484881008303897 acc:0.7680773075641453\r\n",
      "curr: 3500 train loss: 0.45601876776962164 acc:0.7643530419880035\r\n",
      "curr: 4000 train loss: 0.4633911038337642 acc:0.7628092976755811\r\n",
      "curr: 4500 train loss: 0.47061629008934447 acc:0.764496778493668\r\n",
      "curr: 5000 train loss: 0.4730889973378022 acc:0.7644471105778844\r\n",
      "curr: 5500 train loss: 0.4768268542826236 acc:0.7629521905108162\r\n",
      "curr: 6000 train loss: 0.48266721791725514 acc:0.759540076653891\r\n",
      "curr: 6500 train loss: 0.47968247574035827 acc:0.7615751422858021\r\n",
      "curr: 7000 train loss: 0.4801028869411199 acc:0.7607484645050707\r\n",
      "curr: 7500 train loss: 0.482367717172528 acc:0.7585655245967204\r\n",
      "curr: 8000 train loss: 0.48265776288088574 acc:0.7594050743657043\r\n",
      "curr: 8500 train loss: 0.4845859515505437 acc:0.7590871662157394\r\n",
      "curr: 9000 train loss: 0.4845834554957089 acc:0.7595822686368181\r\n",
      "curr: 9500 train loss: 0.4861901160979744 acc:0.7589727397116093\r\n",
      "curr: 10000 train loss: 0.48660122138976175 acc:0.7590240975902409\r\n",
      "curr: 10500 train loss: 0.4859056708353231 acc:0.7615465193791068\r\n",
      "curr: 11000 train loss: 0.4829351242232343 acc:0.7628397418416507\r\n",
      "curr: 11500 train loss: 0.4816389933179588 acc:0.7643683157986262\r\n",
      "curr: 12000 train loss: 0.4814480844306563 acc:0.7636030330805766\r\n",
      "curr: 12500 train loss: 0.4812793412119832 acc:0.7640188784897208\r\n",
      "curr: 13000 train loss: 0.48062830102477766 acc:0.7638643181293746\r\n",
      "curr: 13500 train loss: 0.4789683883636404 acc:0.7651285089993334\r\n",
      "curr: 14000 train loss: 0.477000173137934 acc:0.7658738661524177\r\n",
      "curr: 14500 train loss: 0.475419443077666 acc:0.7667747051927454\r\n",
      "curr: 15000 train loss: 0.47502331829443245 acc:0.7672821811879208\r\n",
      "curr: 15500 train loss: 0.4762835821389367 acc:0.7667247274369395\r\n",
      "curr: 16000 train loss: 0.4761115940355557 acc:0.7670145615899007\r\n",
      "curr: 16500 train loss: 0.4747409977223416 acc:0.7675292406520817\r\n",
      "correct: 12954\r\n",
      "epochs 45 train loss: 0.475585025839109 acc: 0.7669626998223801\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3424238021086797 acc:0.8363273453093812\r\n",
      "curr: 1000 train loss: 0.43380765804905586 acc:0.7632367632367633\r\n",
      "curr: 1500 train loss: 0.418774893046694 acc:0.7728181212524984\r\n",
      "curr: 2000 train loss: 0.40611183213389374 acc:0.7806096951524237\r\n",
      "curr: 2500 train loss: 0.4196346795879917 acc:0.774890043982407\r\n",
      "curr: 3000 train loss: 0.4407717729944577 acc:0.7674108630456514\r\n",
      "curr: 3500 train loss: 0.44941591806337305 acc:0.7626392459297343\r\n",
      "curr: 4000 train loss: 0.45660871162980315 acc:0.7633091727068233\r\n",
      "curr: 4500 train loss: 0.4623610326747214 acc:0.7640524327927127\r\n",
      "curr: 5000 train loss: 0.4659512608328552 acc:0.763247350529894\r\n",
      "curr: 5500 train loss: 0.4695851100502043 acc:0.761861479730958\r\n",
      "curr: 6000 train loss: 0.4752571297750155 acc:0.7592067988668555\r\n",
      "curr: 6500 train loss: 0.474396442205979 acc:0.7603445623750192\r\n",
      "curr: 7000 train loss: 0.47564725143733294 acc:0.7598914440794172\r\n",
      "curr: 7500 train loss: 0.47834002454449215 acc:0.7582988934808692\r\n",
      "curr: 8000 train loss: 0.4784442757318608 acc:0.7584051993500812\r\n",
      "curr: 8500 train loss: 0.4796079745578012 acc:0.7589695329961181\r\n",
      "curr: 9000 train loss: 0.4802816612962645 acc:0.7590267748027997\r\n",
      "curr: 9500 train loss: 0.48136407209386584 acc:0.7577097147668667\r\n",
      "curr: 10000 train loss: 0.4822030122744327 acc:0.7577242275772422\r\n",
      "curr: 10500 train loss: 0.48135129168784235 acc:0.7603085420436149\r\n",
      "curr: 11000 train loss: 0.47913929092182117 acc:0.7619307335696754\r\n",
      "curr: 11500 train loss: 0.4778062531087548 acc:0.7635857751499869\r\n",
      "curr: 12000 train loss: 0.47812320687996257 acc:0.7626864427964336\r\n",
      "curr: 12500 train loss: 0.47829877102001594 acc:0.7634589232861371\r\n",
      "curr: 13000 train loss: 0.4778207366629434 acc:0.7634797323282825\r\n",
      "curr: 13500 train loss: 0.47559295797358253 acc:0.7649803718243093\r\n",
      "curr: 14000 train loss: 0.47387814131216677 acc:0.7663024069709307\r\n",
      "curr: 14500 train loss: 0.47187434121967453 acc:0.7676711950899938\r\n",
      "curr: 15000 train loss: 0.4711457000555465 acc:0.7680821278581428\r\n",
      "curr: 15500 train loss: 0.4723858215374705 acc:0.7671763112057287\r\n",
      "curr: 16000 train loss: 0.4720131243286011 acc:0.7675145303418537\r\n",
      "curr: 16500 train loss: 0.4708561107339727 acc:0.7680140597539543\r\n",
      "correct: 12958\r\n",
      "epochs 46 train loss: 0.473530368570034 acc: 0.7671995263469509\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.35767520589636254 acc:0.8283433133732535\r\n",
      "curr: 1000 train loss: 0.4373347864414082 acc:0.7592407592407593\r\n",
      "curr: 1500 train loss: 0.4220392204718603 acc:0.7694870086608927\r\n",
      "curr: 2000 train loss: 0.4084602925413493 acc:0.7821089455272364\r\n",
      "curr: 2500 train loss: 0.44352071654573283 acc:0.7772890843662535\r\n",
      "curr: 3000 train loss: 0.460829154729438 acc:0.7710763078973676\r\n",
      "curr: 3500 train loss: 0.46849679382197335 acc:0.7677806341045416\r\n",
      "curr: 4000 train loss: 0.4745175871223267 acc:0.7665583604098976\r\n",
      "curr: 4500 train loss: 0.4770198962672414 acc:0.7673850255498778\r\n",
      "curr: 5000 train loss: 0.47789933435844284 acc:0.7656468706258748\r\n",
      "curr: 5500 train loss: 0.4803791418605437 acc:0.7656789674604617\r\n",
      "curr: 6000 train loss: 0.48454022346989667 acc:0.761539743376104\r\n",
      "curr: 6500 train loss: 0.4827475743340814 acc:0.7615751422858021\r\n",
      "curr: 7000 train loss: 0.4831949134706147 acc:0.7611769747178975\r\n",
      "curr: 7500 train loss: 0.4857730741699058 acc:0.7592321023863485\r\n",
      "curr: 8000 train loss: 0.4856145249180077 acc:0.7599050118735158\r\n",
      "curr: 8500 train loss: 0.4869686736751297 acc:0.7595576990942242\r\n",
      "curr: 9000 train loss: 0.48654157140126436 acc:0.7601377624708365\r\n",
      "curr: 9500 train loss: 0.48731275032991556 acc:0.7588674876328807\r\n",
      "curr: 10000 train loss: 0.4876337350953 acc:0.7593240675932407\r\n",
      "curr: 10500 train loss: 0.4863783326420945 acc:0.7621178935339491\r\n",
      "curr: 11000 train loss: 0.48368760114452275 acc:0.7637487501136261\r\n",
      "curr: 11500 train loss: 0.4818555103856629 acc:0.7657594991739849\r\n",
      "curr: 12000 train loss: 0.4813701497972782 acc:0.76518623448046\r\n",
      "curr: 12500 train loss: 0.4810258156318686 acc:0.7655387568994481\r\n",
      "curr: 13000 train loss: 0.4804018407570316 acc:0.7650949926928697\r\n",
      "curr: 13500 train loss: 0.4782209969596941 acc:0.76646174357455\r\n",
      "curr: 14000 train loss: 0.47623162587850637 acc:0.767802299835726\r\n",
      "curr: 14500 train loss: 0.47443169282036 acc:0.7689124887938763\r\n",
      "curr: 15000 train loss: 0.47329315229348506 acc:0.7694820345310313\r\n",
      "curr: 15500 train loss: 0.4746412304222224 acc:0.7684665505451261\r\n",
      "curr: 16000 train loss: 0.4746954030525892 acc:0.7687644522217362\r\n",
      "curr: 16500 train loss: 0.47307210070943684 acc:0.7695291194473062\r\n",
      "correct: 12976\r\n",
      "epochs 47 train loss: 0.4769182134476103 acc: 0.7682652457075192\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3388345359204643 acc:0.844311377245509\r\n",
      "curr: 1000 train loss: 0.4230587775776628 acc:0.7652347652347652\r\n",
      "curr: 1500 train loss: 0.4091742071606745 acc:0.7754830113257828\r\n",
      "curr: 2000 train loss: 0.3977449676918747 acc:0.7851074462768616\r\n",
      "curr: 2500 train loss: 0.4283076754479168 acc:0.7796881247501\r\n",
      "curr: 3000 train loss: 0.44771396605190306 acc:0.7740753082305898\r\n",
      "curr: 3500 train loss: 0.4554625062541166 acc:0.7694944301628106\r\n",
      "curr: 4000 train loss: 0.4618562703392424 acc:0.7695576105973506\r\n",
      "curr: 4500 train loss: 0.46716714240672547 acc:0.7702732726060876\r\n",
      "curr: 5000 train loss: 0.4699462141201761 acc:0.7684463107378524\r\n",
      "curr: 5500 train loss: 0.4725112431170425 acc:0.7667696782403199\r\n",
      "curr: 6000 train loss: 0.4780590168260805 acc:0.7620396600566572\r\n",
      "curr: 6500 train loss: 0.4757463938354531 acc:0.7631133671742809\r\n",
      "curr: 7000 train loss: 0.4764331955009698 acc:0.7623196686187688\r\n",
      "curr: 7500 train loss: 0.4789886002268132 acc:0.7613651513131583\r\n",
      "curr: 8000 train loss: 0.4796522992859702 acc:0.7611548556430446\r\n",
      "curr: 8500 train loss: 0.48185007431404386 acc:0.7610869309493001\r\n",
      "curr: 9000 train loss: 0.48185478094914125 acc:0.7615820464392845\r\n",
      "curr: 9500 train loss: 0.48260379384096364 acc:0.761183033364909\r\n",
      "curr: 10000 train loss: 0.4827978963988385 acc:0.7613238676132387\r\n",
      "curr: 10500 train loss: 0.4820089573120301 acc:0.7636415579468622\r\n",
      "curr: 11000 train loss: 0.47938152460012806 acc:0.7649304608671939\r\n",
      "curr: 11500 train loss: 0.4777278343641611 acc:0.7661942439787844\r\n",
      "curr: 12000 train loss: 0.4776411814171051 acc:0.7656861928172652\r\n",
      "curr: 12500 train loss: 0.4778015211369804 acc:0.7657787377009839\r\n",
      "curr: 13000 train loss: 0.47727236009595775 acc:0.7654026613337436\r\n",
      "curr: 13500 train loss: 0.4752643105134041 acc:0.7670542922746463\r\n",
      "curr: 14000 train loss: 0.47305063161921057 acc:0.7683022641239912\r\n",
      "curr: 14500 train loss: 0.4713688150315757 acc:0.7692572926005103\r\n",
      "curr: 15000 train loss: 0.47066637925092425 acc:0.7699486700886607\r\n",
      "curr: 15500 train loss: 0.47204894535849673 acc:0.7689181343139152\r\n",
      "curr: 16000 train loss: 0.4724854820740783 acc:0.769701893631648\r\n",
      "curr: 16500 train loss: 0.47123371460513636 acc:0.7701351433246469\r\n",
      "correct: 12990\r\n",
      "epochs 48 train loss: 0.47714429815581644 acc: 0.7690941385435168\r\n",
      "curr: 0 train loss: 0.0 acc:0.0\r\n",
      "curr: 500 train loss: 0.3513680705078544 acc:0.8303393213572854\r\n",
      "curr: 1000 train loss: 0.43142795348740215 acc:0.7582417582417582\r\n",
      "curr: 1500 train loss: 0.4180594101905472 acc:0.7701532311792139\r\n",
      "curr: 2000 train loss: 0.4017682851061468 acc:0.7851074462768616\r\n",
      "curr: 2500 train loss: 0.4560518728784266 acc:0.7776889244302279\r\n",
      "curr: 3000 train loss: 0.4715222233140255 acc:0.7714095301566145\r\n",
      "curr: 3500 train loss: 0.4750015593261403 acc:0.7677806341045416\r\n",
      "curr: 4000 train loss: 0.4807987708895642 acc:0.7655586103474131\r\n",
      "curr: 4500 train loss: 0.48341200198249845 acc:0.7662741612974895\r\n",
      "curr: 5000 train loss: 0.4838415651143734 acc:0.7646470705858828\r\n",
      "curr: 5500 train loss: 0.48590381254677406 acc:0.7634975459007454\r\n",
      "curr: 6000 train loss: 0.4913205448427558 acc:0.7610398266955507\r\n",
      "curr: 6500 train loss: 0.48887318335870455 acc:0.76172896477465\r\n",
      "curr: 7000 train loss: 0.4882008711254351 acc:0.7606056277674618\r\n",
      "curr: 7500 train loss: 0.4903167946787485 acc:0.7584322090387948\r\n",
      "curr: 8000 train loss: 0.4904660539273619 acc:0.7595300587426572\r\n",
      "curr: 8500 train loss: 0.49142118981089616 acc:0.7596753323138454\r\n",
      "curr: 9000 train loss: 0.4908708328782694 acc:0.7601377624708365\r\n",
      "curr: 9500 train loss: 0.4914778678032389 acc:0.7590779917903379\r\n",
      "curr: 10000 train loss: 0.4910274823169758 acc:0.7602239776022398\r\n",
      "curr: 10500 train loss: 0.4891553956127957 acc:0.7622131225597563\r\n",
      "curr: 11000 train loss: 0.4858915881496074 acc:0.7633851468048359\r\n",
      "curr: 11500 train loss: 0.484314621030718 acc:0.7648030606034258\r\n",
      "curr: 12000 train loss: 0.4840179499652547 acc:0.7642696441963169\r\n",
      "curr: 12500 train loss: 0.48383383146086967 acc:0.7647388208943284\r\n",
      "curr: 13000 train loss: 0.4831781269377845 acc:0.7642489039304668\r\n",
      "curr: 13500 train loss: 0.48081629436103884 acc:0.7660914006369899\r\n",
      "curr: 14000 train loss: 0.4788621773530847 acc:0.7674451824869652\r\n",
      "curr: 14500 train loss: 0.4766506997022557 acc:0.768636645748569\r\n",
      "curr: 15000 train loss: 0.4754453696466606 acc:0.7693487100859943\r\n",
      "curr: 15500 train loss: 0.4764748003955966 acc:0.7684665505451261\r\n",
      "curr: 16000 train loss: 0.4761117042808467 acc:0.7690144365977126\r\n",
      "curr: 16500 train loss: 0.47493552745089196 acc:0.7692261075086358\r\n",
      "correct: 12972\r\n",
      "epochs 49 train loss: 0.4779955853649029 acc: 0.7680284191829485\r\n",
      "\r\n",
      "Testing..............\r\n",
      "\r\n",
      "data size: 3384\r\n",
      "evaluate >\r\n",
      "81.02\r\n",
      "auc: 12.36 acc: 81.02 precision: 91.44 recall: 54.29 f1: 68.13 \r\n",
      "report:\r\n",
      "              precision    recall  f1-score   support\r\n",
      "\r\n",
      "       clean       0.78      0.97      0.86      2112\r\n",
      "       buggy       0.91      0.54      0.68      1260\r\n",
      "\r\n",
      "    accuracy                           0.81      3372\r\n",
      "   macro avg       0.85      0.76      0.77      3372\r\n",
      "weighted avg       0.83      0.81      0.80      3372\r\n",
      "\r\n",
      "matrix:\r\n",
      "[[2048   64]\r\n",
      " [ 576  684]]\r\n"
     ]
    }
   ],
   "source": [
    "!cd CodeJIT && git pull\n",
    "!python CodeJIT/Main_VULJIT_Detection.py \\\n",
    "--graph_dir='/kaggle/input/codejit-dataset/commits'  \\\n",
    "--train_file='/kaggle/input/data-codejit-split/train_cross_id.txt' \\\n",
    "--test_file='/kaggle/input/data-codejit-split/test_cross_id.txt' \\\n",
    "--model_dir='/kaggle/working/Model' \\\n",
    "--max_epochs=50 \\\n",
    "--model_name='rgcn' \\\n",
    "--hidden_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6beb3c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T10:55:38.382711Z",
     "iopub.status.busy": "2023-08-16T10:55:38.382339Z",
     "iopub.status.idle": "2023-08-16T10:55:38.387092Z",
     "shell.execute_reply": "2023-08-16T10:55:38.386165Z"
    },
    "papermill": {
     "duration": 0.134677,
     "end_time": "2023-08-16T10:55:38.389028",
     "exception": false,
     "start_time": "2023-08-16T10:55:38.254351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cd CodeJIT && git pull\n",
    "# !python CodeJIT/Main_VULJIT_Detection.py \\\n",
    "# --graph_dir='/kaggle/input/codejit-dataset/commits'  \\\n",
    "# --train_file='CodeJIT/test.txt' \\\n",
    "# --test_file='CodeJIT/test.txt' \\\n",
    "# --model_dir='/kaggle/working/Model' \\\n",
    "# --max_epochs=50 \\\n",
    "# --model_name='rgcn' \\\n",
    "# --hidden_size=96"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6200.789229,
   "end_time": "2023-08-16T10:55:39.247644",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-16T09:12:18.458415",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
